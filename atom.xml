<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Gary Wu</title>
  
  <subtitle>运维架构师 - 从入门到放弃</subtitle>
  <link href="/blog/atom.xml" rel="self"/>
  
  <link href="https://garywu520.github.io/blog/"/>
  <updated>2019-06-05T04:29:55.538Z</updated>
  <id>https://garywu520.github.io/blog/</id>
  
  <author>
    <name>Gary Wu</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>UDP抓包工具tcpdump</title>
    <link href="https://garywu520.github.io/blog/2019/06/05/UDP%E6%8A%93%E5%8C%85%E5%B7%A5%E5%85%B7tcpdump/"/>
    <id>https://garywu520.github.io/blog/2019/06/05/UDP抓包工具tcpdump/</id>
    <published>2019-06-05T04:11:51.000Z</published>
    <updated>2019-06-05T04:29:55.538Z</updated>
    
    <content type="html"><![CDATA[<h5 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h5><p>Vultr.com 提供的VPS一直是GFW打压的重灾区，Vultr提供的VPS 无论哪个区域节点，TCP协议基本都被阻断；唯一相对较好的方法是使用UDP，这是因为UDP特性是基于无连接协议。但是每逢“重大节日”，都会被GFW特殊照顾，GFW对付UDP协议的方法就是Qos, 即定时不定时的将UDP包给丢弃。</p><h5 id="关于测试工具"><a href="#关于测试工具" class="headerlink" title="关于测试工具"></a>关于测试工具</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">可使用TCPdump工具进行查看数据包流向情况</span><br><span class="line"></span><br><span class="line">VPS网络-服务端：</span><br><span class="line"><span class="meta">$</span><span class="bash"> tcpdump host 1.10.18.222  </span></span><br><span class="line">[查看VPS网络接收或发送到1.10.18.222主机的UDP数据包] </span><br><span class="line"></span><br><span class="line">本地网络-客户端：</span><br><span class="line"><span class="meta">$</span><span class="bash"> tcpdump -i eth0 port 1024 and dst host <span class="string">"xx.xx.xx.xx"</span>  </span></span><br><span class="line">[查看本地网络通过eth0端口发送到xx.xx.xx.xx主机1024端口的数据包]</span><br></pre></td></tr></table></figure><a id="more"></a><h5 id="关于GFW-Qos样本"><a href="#关于GFW-Qos样本" class="headerlink" title="关于GFW Qos样本"></a>关于GFW Qos样本</h5><p>(1)本地网络[客户端]TCPDump数据：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">11:49:15.945137 IP bogon.44919 &gt; *.vultr.com.1024: UDP, length 1350</span><br><span class="line">11:49:15.945144 IP bogon.44919 &gt; *.vultr.com.1024: UDP, length 1350</span><br><span class="line">11:49:15.945151 IP bogon.44919 &gt; *.vultr.com.1024: UDP, length 1350</span><br><span class="line">11:49:15.945167 IP bogon.44919 &gt; *.vultr.com.1024: UDP, length 1350</span><br><span class="line">11:49:15.945174 IP bogon.44919 &gt; *.vultr.com.1024: UDP, length 1350</span><br><span class="line">11:49:15.945200 IP bogon.44919 &gt; *.vultr.com.1024: UDP, length 1350</span><br><span class="line">11:49:15.945218 IP bogon.44919 &gt; *.vultr.com.1024: UDP, length 1350</span><br><span class="line"></span><br><span class="line">特点：特点：只要有请求，本地网络代理服务会一直向目标主机发送UDP数据包</span><br></pre></td></tr></table></figure><p><strong>(2)VPS网络[服务端]TCPDump数据：</strong></p><p>正常情况 - 数据有去有回</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">11:50:11.359508 IP *.vultr.com.1024 &gt; 1.10.18.222.44919: UDP, length 108</span><br><span class="line">11:50:11.359612 IP *.vultr.com.1024 &gt; 1.10.18.222.44919: UDP, length 60</span><br><span class="line">11:50:11.673463 IP 1.10.18.222.44919 &gt; *.vultr.com.1024: UDP, length 52</span><br><span class="line">11:50:11.682599 IP 1.10.18.222.44919 &gt; *.vultr.com.1024: UDP, length 52</span><br><span class="line">11:50:11.682632 IP 1.10.18.222.44919 &gt; *.vultr.com.1024: UDP, length 52</span><br><span class="line">11:50:12.441615 IP 1.10.18.222.44919 &gt; *.vultr.com.1024: UDP, length 60</span><br><span class="line">11:50:12.465222 IP *.vultr.com.1024 &gt; 1.10.18.222.44919: UDP, length 52</span><br><span class="line">11:50:12.928854 IP *.vultr.com.1024 &gt; 1.10.18.222.44919: UDP, length 84</span><br><span class="line">11:50:12.928931 IP *.vultr.com.1024 &gt; 1.10.18.222.44919: UDP, length 60</span><br><span class="line">11:50:13.252514 IP 1.10.18.222.44919 &gt; *.vultr.com.1024: UDP, length 52</span><br><span class="line">11:50:13.280247 IP *.vultr.com.1024 &gt; 1.10.18.222.44919: UDP, length 60</span><br><span class="line">11:50:13.496401 IP 1.10.18.222.44919 &gt; *.vultr.com.1024: UDP, length 614</span><br><span class="line">11:50:13.521806 IP *.vultr.com.1024 &gt; 1.10.18.222.44919: UDP, length 52</span><br><span class="line">11:50:13.602974 IP 1.10.18.222.44919 &gt; *.vultr.com.1024: UDP, length 52</span><br><span class="line">11:50:13.855926 IP 1.10.18.222.44919 &gt; *.vultr.com.1024: UDP, length 60</span><br><span class="line">11:50:13.883914 IP *.vultr.com.1024 &gt; 1.10.18.222.44919: UDP, length 52</span><br><span class="line"></span><br><span class="line">......</span><br><span class="line"></span><br><span class="line">......</span><br></pre></td></tr></table></figure><p>被GFW Qos的异常情况 - 数据单向发送UDP</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">11:50:11.359508 IP *.vultr.com.1024 &gt; 1.10.18.222.44919: UDP, length 108</span><br><span class="line">11:50:11.359612 IP *.vultr.com.1024 &gt; 1.10.18.222.44919: UDP, length 60</span><br><span class="line">11:50:11.359508 IP *.vultr.com.1024 &gt; 1.10.18.222.44919: UDP, length 108</span><br><span class="line">11:50:11.359612 IP *.vultr.com.1024 &gt; 1.10.18.222.44919: UDP, length 60</span><br><span class="line">11:50:11.359508 IP *.vultr.com.1024 &gt; 1.10.18.222.44919: UDP, length 108</span><br><span class="line">11:50:11.359612 IP *.vultr.com.1024 &gt; 1.10.18.222.44919: UDP, length 60</span><br><span class="line"></span><br><span class="line">......</span><br><span class="line"></span><br><span class="line">......</span><br></pre></td></tr></table></figure><p><strong>如果Qos限制过高情况下，服务端会看到TCPDump不再输出任何信息……</strong></p><p><strong>此时可以说明，客户端发送的所有UDP数据包，都被GFW Qos丢弃，服务端这边根本没有收到</strong></p>]]></content>
    
    <summary type="html">
    
      &lt;h5 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h5&gt;&lt;p&gt;Vultr.com 提供的VPS一直是GFW打压的重灾区，Vultr提供的VPS 无论哪个区域节点，TCP协议基本都被阻断；唯一相对较好的方法是使用UDP，这是因为UDP特性是基于无连接协议。但是每逢“重大节日”，都会被GFW特殊照顾，GFW对付UDP协议的方法就是Qos, 即定时不定时的将UDP包给丢弃。&lt;/p&gt;
&lt;h5 id=&quot;关于测试工具&quot;&gt;&lt;a href=&quot;#关于测试工具&quot; class=&quot;headerlink&quot; title=&quot;关于测试工具&quot;&gt;&lt;/a&gt;关于测试工具&lt;/h5&gt;&lt;figure class=&quot;highlight shell&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;可使用TCPdump工具进行查看数据包流向情况&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;VPS网络-服务端：&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;meta&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;bash&quot;&gt; tcpdump host 1.10.18.222  &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[查看VPS网络接收或发送到1.10.18.222主机的UDP数据包] &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;本地网络-客户端：&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;meta&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;bash&quot;&gt; tcpdump -i eth0 port 1024 and dst host &lt;span class=&quot;string&quot;&gt;&quot;xx.xx.xx.xx&quot;&lt;/span&gt;  &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[查看本地网络通过eth0端口发送到xx.xx.xx.xx主机1024端口的数据包]&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="高级运维" scheme="https://garywu520.github.io/blog/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"/>
    
      <category term="udp" scheme="https://garywu520.github.io/blog/tags/udp/"/>
    
      <category term="tcpdump" scheme="https://garywu520.github.io/blog/tags/tcpdump/"/>
    
      <category term="udp抓包" scheme="https://garywu520.github.io/blog/tags/udp%E6%8A%93%E5%8C%85/"/>
    
      <category term="udp代理" scheme="https://garywu520.github.io/blog/tags/udp%E4%BB%A3%E7%90%86/"/>
    
      <category term="GFW" scheme="https://garywu520.github.io/blog/tags/GFW/"/>
    
  </entry>
  
  <entry>
    <title>UDP Ping工具</title>
    <link href="https://garywu520.github.io/blog/2019/06/04/UDP-Ping%E5%B7%A5%E5%85%B7/"/>
    <id>https://garywu520.github.io/blog/2019/06/04/UDP-Ping工具/</id>
    <published>2019-06-04T09:22:27.000Z</published>
    <updated>2019-06-04T09:24:43.035Z</updated>
    
    <content type="html"><![CDATA[<h5 id="服务端-配置"><a href="#服务端-配置" class="headerlink" title="服务端-配置"></a>服务端-配置</h5><p>(1) 安装socat</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum <span class="keyword">install</span> -y socat</span><br></pre></td></tr></table></figure><p>(2) 防火墙开启udp 12213端口</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">iptables -A INPUT -<span class="selector-tag">p</span> udp --dport <span class="number">12213</span> -j ACCEPT      </span><br><span class="line">iptables -A OUTPUT -<span class="selector-tag">p</span> udp --sport <span class="number">12213</span> -j ACCEPT</span><br></pre></td></tr></table></figure><a id="more"></a><p>(3) 配置udp响应服务</p><p>cat   /etc/systemd/system/udpping.service</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[Unit]</span><br><span class="line"><span class="attribute">Description</span>=UDP Ping</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line"><span class="attribute">ExecStart</span>=/usr/bin/socat UDP-LISTEN:12213,fork PIPE</span><br><span class="line"><span class="attribute">Restart</span>=always</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line"><span class="attribute">WantedBy</span>=multi-user.target</span><br></pre></td></tr></table></figure><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">systemctl <span class="builtin-name">enable</span> udpping</span><br><span class="line">systemctl start udpping</span><br><span class="line">systemctl status udpping</span><br><span class="line">netstat -lntup|grep 12213</span><br></pre></td></tr></table></figure><h5 id="客户端使用"><a href="#客户端使用" class="headerlink" title="客户端使用"></a>客户端使用</h5><p>(1) Git Clone项目</p><p>​      项目地址：<a href="https://github.com/wangyu-/UDPping" target="_blank" rel="noopener">UDPping</a></p><p>(2) 使用</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# /opt/UDPping-master/udpping.py xx.xx.xx.xx 12213</span><br><span class="line">UDPping 45.76.47.218 via<span class="built_in"> port </span>12213 with 64 bytes of payload</span><br><span class="line">Reply <span class="keyword">from</span> xx.xx.xx.xx <span class="attribute">seq</span>=0 <span class="attribute">time</span>=224.34 ms</span><br><span class="line">Reply <span class="keyword">from</span> xx.xx.xx.xx <span class="attribute">seq</span>=1 <span class="attribute">time</span>=223.00 ms</span><br><span class="line">Reply <span class="keyword">from</span> xx.xx.xx.xx <span class="attribute">seq</span>=2 <span class="attribute">time</span>=220.25 ms</span><br><span class="line">Reply <span class="keyword">from</span> xx.xx.xx.xx <span class="attribute">seq</span>=3 <span class="attribute">time</span>=221.82 ms</span><br><span class="line">Reply <span class="keyword">from</span> xx.xx.xx.xx <span class="attribute">seq</span>=4 <span class="attribute">time</span>=220.44 ms</span><br><span class="line"></span><br><span class="line">---<span class="built_in"> ping </span>statistics ---</span><br><span class="line">5 packets transmitted, 5 received, 0.00% packet loss</span><br><span class="line">rtt min/avg/max = 220.25/221.97/224.34 ms</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h5 id=&quot;服务端-配置&quot;&gt;&lt;a href=&quot;#服务端-配置&quot; class=&quot;headerlink&quot; title=&quot;服务端-配置&quot;&gt;&lt;/a&gt;服务端-配置&lt;/h5&gt;&lt;p&gt;(1) 安装socat&lt;/p&gt;
&lt;figure class=&quot;highlight cmake&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;yum &lt;span class=&quot;keyword&quot;&gt;install&lt;/span&gt; -y socat&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;p&gt;(2) 防火墙开启udp 12213端口&lt;/p&gt;
&lt;figure class=&quot;highlight stylus&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;iptables -A INPUT -&lt;span class=&quot;selector-tag&quot;&gt;p&lt;/span&gt; udp --dport &lt;span class=&quot;number&quot;&gt;12213&lt;/span&gt; -j ACCEPT      &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;iptables -A OUTPUT -&lt;span class=&quot;selector-tag&quot;&gt;p&lt;/span&gt; udp --sport &lt;span class=&quot;number&quot;&gt;12213&lt;/span&gt; -j ACCEPT&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="高级运维" scheme="https://garywu520.github.io/blog/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"/>
    
      <category term="UDP" scheme="https://garywu520.github.io/blog/tags/UDP/"/>
    
      <category term="UDP Ping" scheme="https://garywu520.github.io/blog/tags/UDP-Ping/"/>
    
      <category term="Ping" scheme="https://garywu520.github.io/blog/tags/Ping/"/>
    
      <category term="socat" scheme="https://garywu520.github.io/blog/tags/socat/"/>
    
  </entry>
  
  <entry>
    <title>zabbix监控TraceRoute数据</title>
    <link href="https://garywu520.github.io/blog/2019/05/31/zabbix%E7%9B%91%E6%8E%A7TraceRoute%E6%95%B0%E6%8D%AE/"/>
    <id>https://garywu520.github.io/blog/2019/05/31/zabbix监控TraceRoute数据/</id>
    <published>2019-05-31T03:11:28.000Z</published>
    <updated>2019-05-31T03:26:54.535Z</updated>
    
    <content type="html"><![CDATA[<h4 id="zabbix监控TraceRoute数据"><a href="#zabbix监控TraceRoute数据" class="headerlink" title="zabbix监控TraceRoute数据"></a>zabbix监控TraceRoute数据</h4><figure class="highlight armasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">Trace</span>工具：<span class="keyword">BestTrace </span>【MTR同理】</span><br></pre></td></tr></table></figure><p>前言</p><figure class="highlight brainfuck"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">zabbix监控traceroute数据是由zabbix</span> <span class="comment">server端向“目标主机”发起的traceroute</span></span><br><span class="line"><span class="comment">为了测试多个机房之间的网络情况，通常这个目标主机应该是不同机房的proxy端的代理</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">因此，假设zabbix</span> <span class="comment">server为A机房，proxy分别为B机房和C机房，那么监控流向如下：</span></span><br><span class="line"><span class="comment">A</span> <span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="comment">traceroute</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span>&gt;<span class="comment">B</span></span><br><span class="line"><span class="comment">A</span> <span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="comment">traceroute</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span>&gt;<span class="comment">C</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">因此，就会出现一个问题：即假设A</span><span class="literal">-</span><span class="literal">-</span>&gt;<span class="comment">B</span> <span class="comment">的traceroute出现问题，并不能一定说明，B有问题，也不能说明A一定有问题。此时就需要在不同的proxy端，通过脚本向其他两个不同机房进行反Traceroute</span><span class="string">,</span><span class="comment">这样就有了数据对比，方便的确定具体是哪个机房网络出现故障。</span></span><br></pre></td></tr></table></figure><a id="more"></a><h4 id="1-在zabbix-server服务器上安装besttrace"><a href="#1-在zabbix-server服务器上安装besttrace" class="headerlink" title="(1)在zabbix server服务器上安装besttrace"></a>(1)在zabbix server服务器上安装besttrace</h4><figure class="highlight armasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">wget</span> http://cdn.ipip.net/<span class="number">17</span>mon/<span class="keyword">besttrace4linux.zip</span></span><br><span class="line"><span class="keyword">unzip </span><span class="keyword">besttrace4linux.zip</span></span><br><span class="line"><span class="keyword">chmod </span>+x <span class="keyword">besttrace</span></span><br><span class="line"><span class="keyword">mv </span><span class="keyword">besttrace </span>/usr/sbin/</span><br><span class="line"></span><br><span class="line">#让zabbix有权限执行<span class="keyword">besttrace命令</span></span><br><span class="line"><span class="keyword">chmod </span>+s /usr/sbin/<span class="keyword">besttrace</span></span><br></pre></td></tr></table></figure><h4 id="2-编写脚本"><a href="#2-编写脚本" class="headerlink" title="(2)编写脚本"></a>(2)编写脚本</h4><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">查看zabbix server服务器配置文件中的外部脚本路径，如：/var/<span class="class"><span class="keyword">lib</span>/<span class="title">zabbix</span>/<span class="title">externalscripts</span></span></span><br></pre></td></tr></table></figure><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /var/<span class="class"><span class="keyword">lib</span>/<span class="title">zabbix</span>/<span class="title">externalscripts</span></span></span><br></pre></td></tr></table></figure><p>cat besttrace.sh</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line">IP=<span class="variable">$1</span></span><br><span class="line"></span><br><span class="line">/usr/sbin/besttrace -q 1 <span class="variable">$IP</span></span><br></pre></td></tr></table></figure><p>修改脚本权限</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">chmod</span> +<span class="selector-tag">x</span> <span class="selector-tag">besttrace</span><span class="selector-class">.sh</span></span><br><span class="line"><span class="selector-tag">chown</span> <span class="selector-tag">zabbix</span><span class="selector-pseudo">:zabbix</span> <span class="selector-tag">besttrace</span><span class="selector-class">.sh</span></span><br></pre></td></tr></table></figure><h4 id="3-zabbix-web添加自定义模板"><a href="#3-zabbix-web添加自定义模板" class="headerlink" title="(3) zabbix web添加自定义模板"></a>(3) zabbix web添加自定义模板</h4><p>模板中创建监控项</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Name: BestTrace</span><br><span class="line">Type: External check</span><br><span class="line">Key: besttrace.sh[<span class="string">"&#123;HOST.IP&#125;"</span>]</span><br><span class="line">Type of information: Text</span><br><span class="line">时间间隔：90</span><br><span class="line">应用集：BestTrace</span><br></pre></td></tr></table></figure><h4 id="4-将主机应用模板"><a href="#4-将主机应用模板" class="headerlink" title="(4) 将主机应用模板"></a>(4) 将主机应用模板</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">稍等片刻，查看主机最新数据即可。</span><br></pre></td></tr></table></figure><p>参考：<a href="https://jeremyverda.net/traceroute-with-zabbix-and-mtr/" target="_blank" rel="noopener">Jérémy Verda’s IT Blog</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;zabbix监控TraceRoute数据&quot;&gt;&lt;a href=&quot;#zabbix监控TraceRoute数据&quot; class=&quot;headerlink&quot; title=&quot;zabbix监控TraceRoute数据&quot;&gt;&lt;/a&gt;zabbix监控TraceRoute数据&lt;/h4&gt;&lt;figure class=&quot;highlight armasm&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;symbol&quot;&gt;Trace&lt;/span&gt;工具：&lt;span class=&quot;keyword&quot;&gt;BestTrace &lt;/span&gt;【MTR同理】&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;p&gt;前言&lt;/p&gt;
&lt;figure class=&quot;highlight brainfuck&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;zabbix监控traceroute数据是由zabbix&lt;/span&gt; &lt;span class=&quot;comment&quot;&gt;server端向“目标主机”发起的traceroute&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;为了测试多个机房之间的网络情况，通常这个目标主机应该是不同机房的proxy端的代理&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;因此，假设zabbix&lt;/span&gt; &lt;span class=&quot;comment&quot;&gt;server为A机房，proxy分别为B机房和C机房，那么监控流向如下：&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;A&lt;/span&gt; &lt;span class=&quot;literal&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;literal&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;literal&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;traceroute&lt;/span&gt;&lt;span class=&quot;literal&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;literal&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;literal&quot;&gt;-&lt;/span&gt;&amp;gt;&lt;span class=&quot;comment&quot;&gt;B&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;A&lt;/span&gt; &lt;span class=&quot;literal&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;literal&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;literal&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;traceroute&lt;/span&gt;&lt;span class=&quot;literal&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;literal&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;literal&quot;&gt;-&lt;/span&gt;&amp;gt;&lt;span class=&quot;comment&quot;&gt;C&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;因此，就会出现一个问题：即假设A&lt;/span&gt;&lt;span class=&quot;literal&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;literal&quot;&gt;-&lt;/span&gt;&amp;gt;&lt;span class=&quot;comment&quot;&gt;B&lt;/span&gt; &lt;span class=&quot;comment&quot;&gt;的traceroute出现问题，并不能一定说明，B有问题，也不能说明A一定有问题。此时就需要在不同的proxy端，通过脚本向其他两个不同机房进行反Traceroute&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;这样就有了数据对比，方便的确定具体是哪个机房网络出现故障。&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="高级运维" scheme="https://garywu520.github.io/blog/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"/>
    
      <category term="zabbix" scheme="https://garywu520.github.io/blog/tags/zabbix/"/>
    
      <category term="traceroute" scheme="https://garywu520.github.io/blog/tags/traceroute/"/>
    
      <category term="besttrace" scheme="https://garywu520.github.io/blog/tags/besttrace/"/>
    
      <category term="MTR" scheme="https://garywu520.github.io/blog/tags/MTR/"/>
    
  </entry>
  
  <entry>
    <title>SSL证书自签shell</title>
    <link href="https://garywu520.github.io/blog/2019/05/15/SSL%E8%AF%81%E4%B9%A6%E8%87%AA%E7%AD%BEshell/"/>
    <id>https://garywu520.github.io/blog/2019/05/15/SSL证书自签shell/</id>
    <published>2019-05-15T06:14:34.000Z</published>
    <updated>2019-05-15T06:24:13.387Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>使用</p></blockquote><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hostname ssl]# <span class="keyword">sh</span> ssl_shell.<span class="keyword">sh</span> </span><br><span class="line">USAGE: <span class="keyword">sh</span> <span class="keyword">shell</span>.<span class="keyword">sh</span> IP <span class="string">'Password'</span></span><br></pre></td></tr></table></figure><p>‘Password’ 字段是指SSL生成的证书密码</p><a id="more"></a><blockquote><p>shell脚本</p></blockquote><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[root@hostname ssl]# <span class="keyword">cat</span> <span class="keyword">shell</span>.<span class="keyword">sh</span> </span><br><span class="line"><span class="keyword">if</span> [ $# != 2 ];then</span><br><span class="line">   echo <span class="string">"USAGE: sh $0 IP 'Password'"</span></span><br><span class="line">   <span class="keyword">exit</span> 1;</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">CNIP=<span class="variable">$1</span></span><br><span class="line">PASS=<span class="variable">$2</span></span><br><span class="line">echo <span class="string">"3秒后,开始生成根证书...."</span></span><br><span class="line"><span class="keyword">sleep</span> 3</span><br><span class="line">openssl genrsa -<span class="keyword">out</span> cakey.pem 4096</span><br><span class="line">openssl req -new -x509 -key cakey.pem -<span class="keyword">out</span> cacert.pem -subj <span class="string">"/C=HK/ST=Hongkong/L=Hongkong/O=NASA/OU=Dev/CN=$CNIP/emailAddress=hk_dev@nasa.com"</span></span><br><span class="line"></span><br><span class="line">echo <span class="string">"3秒后,开始生成csr以及证书签署..."</span></span><br><span class="line"><span class="keyword">sleep</span> 3</span><br><span class="line">openssl genrsa -<span class="keyword">out</span> server.key 4096</span><br><span class="line">openssl req -new -passout pass:<span class="string">"$PASS"</span> -key server.key -<span class="keyword">out</span> server.csr -subj <span class="string">"/C=HK/ST=Hongkong/L=Hongkong/O=NASA/OU=Dev/CN=$CNIP/emailAddress=hk_dev@nasa.com"</span></span><br><span class="line">openssl x509 -req -<span class="keyword">in</span> server.csr -<span class="keyword">CA</span> cacert.pem -CAkey cakey.pem -CAcreateserial -<span class="keyword">out</span> server.crt -days 3650</span><br><span class="line"></span><br><span class="line">echo <span class="string">"3秒后,开始生成dhparam.pem..."</span></span><br><span class="line"><span class="keyword">sleep</span> 3</span><br><span class="line">openssl dhparam -dsaparam -<span class="keyword">out</span> dhparam.pem 4096</span><br><span class="line"></span><br><span class="line">echo <span class="string">"自签证书已完成,详情如下:..."</span></span><br><span class="line"><span class="keyword">ls</span> -lh dh* server*</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;使用&lt;/p&gt;
&lt;/blockquote&gt;
&lt;figure class=&quot;highlight vim&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[root@hostname ssl]# &lt;span class=&quot;keyword&quot;&gt;sh&lt;/span&gt; ssl_shell.&lt;span class=&quot;keyword&quot;&gt;sh&lt;/span&gt; &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;USAGE: &lt;span class=&quot;keyword&quot;&gt;sh&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;shell&lt;/span&gt;.&lt;span class=&quot;keyword&quot;&gt;sh&lt;/span&gt; IP &lt;span class=&quot;string&quot;&gt;&#39;Password&#39;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;p&gt;‘Password’ 字段是指SSL生成的证书密码&lt;/p&gt;
    
    </summary>
    
    
      <category term="openssl" scheme="https://garywu520.github.io/blog/tags/openssl/"/>
    
      <category term="ssl" scheme="https://garywu520.github.io/blog/tags/ssl/"/>
    
      <category term="crt" scheme="https://garywu520.github.io/blog/tags/crt/"/>
    
      <category term="ca" scheme="https://garywu520.github.io/blog/tags/ca/"/>
    
      <category term="自签证书" scheme="https://garywu520.github.io/blog/tags/%E8%87%AA%E7%AD%BE%E8%AF%81%E4%B9%A6/"/>
    
      <category term="shell" scheme="https://garywu520.github.io/blog/tags/shell/"/>
    
  </entry>
  
  <entry>
    <title>递归缓存DNS-SmartDNS</title>
    <link href="https://garywu520.github.io/blog/2019/04/23/%E9%80%92%E5%BD%92%E7%BC%93%E5%AD%98DNS-SmartDNS/"/>
    <id>https://garywu520.github.io/blog/2019/04/23/递归缓存DNS-SmartDNS/</id>
    <published>2019-04-23T03:09:54.000Z</published>
    <updated>2019-04-23T03:13:27.040Z</updated>
    
    <content type="html"><![CDATA[<p>闲来无事，注意到一个个人DNS项目，拿来玩玩</p><h5 id="SmartDNS"><a href="#SmartDNS" class="headerlink" title="SmartDNS"></a>SmartDNS</h5><p>github项目：<a href="https://github.com/pymumu/smartdns" target="_blank" rel="noopener">SmartDNS</a></p><p>github releases: <a href="https://github.com/pymumu/smartdns/releases" target="_blank" rel="noopener">SmartDNS</a></p><a id="more"></a><h5 id="x86-64安装"><a href="#x86-64安装" class="headerlink" title="x86_64安装"></a>x86_64安装</h5><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tar zxf smartdns<span class="selector-class">.xxxxxxxx</span><span class="selector-class">.x86-64</span><span class="selector-class">.tar</span><span class="selector-class">.gz</span></span><br><span class="line">cd smartdns</span><br><span class="line">chmod +x ./install</span><br><span class="line">./install -i</span><br></pre></td></tr></table></figure><h5 id="配置参数"><a href="#配置参数" class="headerlink" title="配置参数"></a>配置参数</h5><p>参考：<a href="https://github.com/pymumu/smartdns#%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0" target="_blank" rel="noopener">SmartDNS配置参数</a></p><p>grep -v ‘#’ /etc/smartdns/smartdns.conf </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">server-name smartdns</span><br><span class="line">conf-file /etc/smartdns/conf.d/*.conf</span><br><span class="line">bind 10.0.10.101:53</span><br><span class="line">tcp-idle-time 120</span><br><span class="line">cache-size 512</span><br><span class="line">prefetch-domain yes</span><br><span class="line">force-AAAA-SOA yes</span><br><span class="line">rr-ttl 300</span><br><span class="line">rr-ttl-min 60</span><br><span class="line">rr-ttl-max 600</span><br><span class="line">log-level error</span><br><span class="line">log-file /var/log/smartdns.log</span><br><span class="line">log-size 128k</span><br><span class="line">log-num 5</span><br><span class="line">audit-enable yes</span><br><span class="line">audit-file /var/log/smartdns-audit.log    #解析日志存放目录</span><br><span class="line">audit-size 128k   #解析日志大小</span><br><span class="line">audit-num 2       #解析日志存档数量</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">上级DNS</span></span><br><span class="line">server-tls 8.8.8.8 -blacklist-ip -check-edns -group tls</span><br><span class="line">server-tls 1.0.0.1 -blacklist-ip -check-edns -group tls</span><br><span class="line">server-https https://cloudflare-dns.com/dns-query -blacklist-ip -check-edns -group https</span><br></pre></td></tr></table></figure><h5 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h5><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl <span class="builtin-name">enable</span> smartdns</span><br><span class="line">systemctl start smartdns</span><br></pre></td></tr></table></figure><h5 id="启动错误解决"><a href="#启动错误解决" class="headerlink" title="启动错误解决"></a>启动错误解决</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> smartdns --<span class="built_in">help</span></span></span><br><span class="line">smartdns: error while loading shared libraries: libssl.so.1.0.0: cannot open shared object file: No such file or directory</span><br></pre></td></tr></table></figure><p>解决方法</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">yum install zlib-devel</span><br><span class="line">wget https://www.openssl.org/source/old/1.0.1/openssl-1.0.1e.tar.gz</span><br><span class="line">cd openssl-1.0.1e</span><br><span class="line">./config shared zlib-dynamic  #生成Makefile文件。</span><br><span class="line">make       #生成生成libssl.so.1.0.0和libcrypto.so.1.0.0</span><br><span class="line">cp libssl.so.1.0.0 libcrypto.so.1.0.0 /usr/lib64/</span><br></pre></td></tr></table></figure><h5 id="FAQ"><a href="#FAQ" class="headerlink" title="FAQ"></a>FAQ</h5><p>高级配置：<a href="https://github.com/pymumu/smartdns#%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0" target="_blank" rel="noopener">参考</a></p><h5 id="SmartDNS压测结果"><a href="#SmartDNS压测结果" class="headerlink" title="SmartDNS压测结果"></a>SmartDNS压测结果</h5><ul><li>系统CentOS7</li><li>工具：queryperf</li><li>查询量级：5,505,024</li><li>查询成功率：5,505,024</li><li>每分钟执行次数：36966.632492-46034.007736 qps</li><li>总耗费时间：1m59.590s - 2m28.922s</li></ul><p>整体来讲，压测结果还算可以，作为公司内部缓存DNS足矣，稳定性仍需测试</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;闲来无事，注意到一个个人DNS项目，拿来玩玩&lt;/p&gt;
&lt;h5 id=&quot;SmartDNS&quot;&gt;&lt;a href=&quot;#SmartDNS&quot; class=&quot;headerlink&quot; title=&quot;SmartDNS&quot;&gt;&lt;/a&gt;SmartDNS&lt;/h5&gt;&lt;p&gt;github项目：&lt;a href=&quot;https://github.com/pymumu/smartdns&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;SmartDNS&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;github releases: &lt;a href=&quot;https://github.com/pymumu/smartdns/releases&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;SmartDNS&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="高级运维" scheme="https://garywu520.github.io/blog/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"/>
    
      <category term="DNS" scheme="https://garywu520.github.io/blog/tags/DNS/"/>
    
      <category term="dig" scheme="https://garywu520.github.io/blog/tags/dig/"/>
    
      <category term="queryperf" scheme="https://garywu520.github.io/blog/tags/queryperf/"/>
    
  </entry>
  
  <entry>
    <title>ES集群监控-总结</title>
    <link href="https://garywu520.github.io/blog/2019/04/18/ES%E9%9B%86%E7%BE%A4%E7%9B%91%E6%8E%A7-%E6%80%BB%E7%BB%93/"/>
    <id>https://garywu520.github.io/blog/2019/04/18/ES集群监控-总结/</id>
    <published>2019-04-18T03:33:07.000Z</published>
    <updated>2019-04-19T02:14:53.950Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>ES监控的最主要作用是用于保障基于ES的服务正常运行以及在出现问题时为工程师提供解决问题的依据，进而快速定位及解决问题</p></blockquote><a id="more"></a><h4 id="集群监控"><a href="#集群监控" class="headerlink" title="集群监控"></a>集群监控</h4><p>集群监控主要包括2个方面的内容，分别是：集群健康状态 和 集群统计信息</p><h5 id="①-集群健康状态信息-API获取："><a href="#①-集群健康状态信息-API获取：" class="headerlink" title="① 集群健康状态信息-API获取："></a>① 集群健康状态信息-API获取：</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -XGET http://ip:9200/_cluster/health?pretty</span><br></pre></td></tr></table></figure><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"cluster_name"</span> : <span class="string">"xxxxxx"</span>,</span><br><span class="line">  <span class="attr">"status"</span> : <span class="string">"green"</span>,</span><br><span class="line">  <span class="attr">"timed_out"</span> : <span class="literal">false</span>,</span><br><span class="line">  <span class="attr">"number_of_nodes"</span> : <span class="number">8</span>,</span><br><span class="line">  <span class="attr">"number_of_data_nodes"</span> : <span class="number">8</span>,</span><br><span class="line">  <span class="attr">"active_primary_shards"</span> : <span class="number">12169</span>,</span><br><span class="line">  <span class="attr">"active_shards"</span> : <span class="number">24338</span>,</span><br><span class="line">  <span class="attr">"relocating_shards"</span> : <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"initializing_shards"</span> : <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"unassigned_shards"</span> : <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"delayed_unassigned_shards"</span> : <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"number_of_pending_tasks"</span> : <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"number_of_in_flight_fetch"</span> : <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"task_max_waiting_in_queue_millis"</span> : <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"active_shards_percent_as_number"</span> : <span class="number">100.0</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><table><thead><tr><th align="center">指标</th><th align="center">说明</th></tr></thead><tbody><tr><td align="center">status</td><td align="center">集群状态：green、yellow和red</td></tr><tr><td align="center">number_of_nodes / number_of_data_nodes</td><td align="center">集群节点数 / 数据节点数</td></tr><tr><td align="center">active_primary_shards</td><td align="center">集群中所有活跃的主分片数</td></tr><tr><td align="center">active_shards</td><td align="center">集群中所有活跃的分片数</td></tr><tr><td align="center">relocating_shards</td><td align="center">当前节点迁往其他节点的分片数量,通常为0. 当有节点加入或退出时该值会增加</td></tr><tr><td align="center">initializing_shards</td><td align="center">正在初始化的分片</td></tr><tr><td align="center">unassigned_shards</td><td align="center">未分配的分片数，通常为0；当有某个节点的副本分片丢失该值就会增加</td></tr><tr><td align="center">number_of_pending_tasks</td><td align="center">指主节点创建索引并分配shards等任务，如果该指标数值一直未减小代表集群存在不稳定因素</td></tr><tr><td align="center">active_shards_percent_as_number</td><td align="center">集群分片健康度； 活跃分片数占总分片数的比例</td></tr></tbody></table><table><thead><tr><th align="center">status</th><th align="center">说明</th></tr></thead><tbody><tr><td align="center">green</td><td align="center">所有的分片和副本均已分配，集群100%可用</td></tr><tr><td align="center">yellow</td><td align="center">所有的主分片正常，但至少有一个副本缺失，此时搜索结果依然是完整的，数据不会丢失。但高可用集群在某种程度上被弱化。</td></tr><tr><td align="center">red</td><td align="center">至少一个主分片(以及它的全部副本)都已经缺失，这意味着集群存在数据缺失，搜索只能返回部分数据，而分配到这个分片上的写入请求会返回异常</td></tr></tbody></table><h5 id="②-集群统计信息-API获取"><a href="#②-集群统计信息-API获取" class="headerlink" title="② 集群统计信息-API获取"></a>② 集群统计信息-API获取</h5><p>集群统计信息包含：文档数、分片数、资源使用情况等</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -XGET  http://ip:9200/_cluster/stats?pretty</span><br></pre></td></tr></table></figure><table><thead><tr><th align="center">指标</th><th align="center">说明</th></tr></thead><tbody><tr><td align="center">indices.count</td><td align="center">索引总数</td></tr><tr><td align="center">indices.shards.total</td><td align="center">分片总数</td></tr><tr><td align="center">ubduces.shards.primaries</td><td align="center">主分片数量</td></tr><tr><td align="center">docs.count</td><td align="center">文档总数</td></tr><tr><td align="center">store.size_in_bytes</td><td align="center">数据总存储容量</td></tr><tr><td align="center">segments.count</td><td align="center">段总数</td></tr><tr><td align="center">nodes.count.total</td><td align="center">总节点数</td></tr><tr><td align="center">nodes.count.data</td><td align="center">数据节点数</td></tr><tr><td align="center">nodes.process.cpu.percent</td><td align="center">节点CPU使用率</td></tr><tr><td align="center">fs.total_in_bytes</td><td align="center">文件系统使用总容量</td></tr><tr><td align="center">fs.free_in_bytes</td><td align="center">文件系统剩余总容量</td></tr></tbody></table><p>在运行 Elasticsearch 时，内存是您要密切监控的关键资源之一。 Elasticsearch 和 Lucene 以两种方式利用节点上的所有可用 RAM：JVM heap 和文件系统缓存。 Elasticsearch 运行在Java虚拟机（JVM）中，这意味着JVM垃圾回收的持续时间和频率将成为其他重要的监控领域。 所以，仍需关注内存/CPU使用，指标值为：</p><p>① nodes.mem.used_percent</p><p>② nodes.process.cpu.percent</p><p>③ nodes.jvm.mem.heap_used</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;ES监控的最主要作用是用于保障基于ES的服务正常运行以及在出现问题时为工程师提供解决问题的依据，进而快速定位及解决问题&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="高级运维" scheme="https://garywu520.github.io/blog/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"/>
    
      <category term="es" scheme="https://garywu520.github.io/blog/tags/es/"/>
    
      <category term="elk" scheme="https://garywu520.github.io/blog/tags/elk/"/>
    
      <category term="elasticsearch" scheme="https://garywu520.github.io/blog/tags/elasticsearch/"/>
    
      <category term="es集群" scheme="https://garywu520.github.io/blog/tags/es%E9%9B%86%E7%BE%A4/"/>
    
      <category term="zabbix监控" scheme="https://garywu520.github.io/blog/tags/zabbix%E7%9B%91%E6%8E%A7/"/>
    
  </entry>
  
  <entry>
    <title>解决ES集群存在UNASSIGNED的问题</title>
    <link href="https://garywu520.github.io/blog/2019/04/13/%E8%A7%A3%E5%86%B3ES%E9%9B%86%E7%BE%A4%E5%AD%98%E5%9C%A8UNASSIGNED%E7%9A%84%E9%97%AE%E9%A2%98/"/>
    <id>https://garywu520.github.io/blog/2019/04/13/解决ES集群存在UNASSIGNED的问题/</id>
    <published>2019-04-12T23:48:40.000Z</published>
    <updated>2019-04-13T00:27:38.003Z</updated>
    
    <content type="html"><![CDATA[<p>当ES集群出现red或yellow状态的时候，出现大量的UNASSIGNED未注册分片解决方案</p><h5 id="确保集群正常"><a href="#确保集群正常" class="headerlink" title="确保集群正常"></a>确保集群正常</h5><ul><li>服务正常启动</li><li>9200端口正常监听</li></ul><a id="more"></a><h5 id="查看ES集群状态"><a href="#查看ES集群状态" class="headerlink" title="查看ES集群状态"></a>查看ES集群状态</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -XGET 'http://localhost:9200/_cluster/health?pretty'</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[root@lfh-R720-51 ~]# curl -XGET 'http://server_ip:9200/_cluster/health?pretty'</span><br><span class="line">&#123;</span><br><span class="line">  "cluster_name" : "cluster",</span><br><span class="line">  "status" : "red",   #ES集群当前状态为red,表示不正常</span><br><span class="line">  "timed_out" : false,</span><br><span class="line">  "number_of_nodes" : 8,</span><br><span class="line">  "number_of_data_nodes" : 8,</span><br><span class="line">  "active_primary_shards" : 12097,</span><br><span class="line">  "active_shards" : 24194,</span><br><span class="line">  "relocating_shards" : 2,</span><br><span class="line">  "initializing_shards" : 0,</span><br><span class="line">  "unassigned_shards" : 6,     #这里显示未注册分片数量</span><br><span class="line">  "delayed_unassigned_shards" : 0,</span><br><span class="line">  "number_of_pending_tasks" : 305989,</span><br><span class="line">  "number_of_in_flight_fetch" : 0,</span><br><span class="line">  "task_max_waiting_in_queue_millis" : 417944,</span><br><span class="line">  "active_shards_percent_as_number" : 100.0</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="查看unassigned-未注册-分片信息"><a href="#查看unassigned-未注册-分片信息" class="headerlink" title="查看unassigned(未注册)分片信息"></a>查看unassigned(未注册)分片信息</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -XGET 'http://server_ip:9200/_cat/shards' | grep UNASSIGNED</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">        索引名称                                        shard序号  状态：未注册</span><br><span class="line">logstash-exc-crash-2018.04.30                            3 p     UNASSIGNED                 </span><br><span class="line">logstash-exc-crash-2018.02.28                            1 p     UNASSIGNED               </span><br><span class="line">logstash-exc-crash-2018.02.28                            1 r     UNASSIGNED   </span><br><span class="line">logstash-exc-crash-2018.02.20                            1 p     UNASSIGNED</span><br></pre></td></tr></table></figure><h5 id="获取ES集群或单一节点唯一标识"><a href="#获取ES集群或单一节点唯一标识" class="headerlink" title="获取ES集群或单一节点唯一标识"></a>获取ES集群或单一节点唯一标识</h5><p>这个唯一标识，在稍后处理shards时要用到</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -XGET 'http://server_ip:9200/_nodes/stats?pretty'|head</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">一般类似：</span><br><span class="line">nodes" : &#123;</span><br><span class="line">4    "02Bp5yXsQVO2BlUgYViYvt" : &#123;</span><br><span class="line">9      "timestamp" : 1555114009778,</span><br><span class="line"></span><br><span class="line">注：这里的"02Bp5yXsQVO2BlUgYViYvt" 就是唯一标识了</span><br></pre></td></tr></table></figure><h5 id="处理unassigned分片信息"><a href="#处理unassigned分片信息" class="headerlink" title="处理unassigned分片信息"></a>处理unassigned分片信息</h5><p>(1) 如果列出的unassigned分片信息，数据较老，并且可以接受索引删除，那么直接使用命令删除掉就可以了</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -XDELETE  'http://server_ip:9200/logstash-exc-crash-2018.02.28'</span><br></pre></td></tr></table></figure><p>正常的情况下，删除后会返回true</p><p>(2)[推荐] 如果数据较新，不容忍数据丢失，那么就需要强制reroute</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">curl -XPOST 'server_ip:9200/_cluster/reroute' -d '&#123;</span><br><span class="line">        "commands" : [ &#123;</span><br><span class="line">              "allocate" : &#123;</span><br><span class="line">              "index" : "logstash-exc-crash-2018.04.30",</span><br><span class="line">              "shard" : 3,</span><br><span class="line">              "node" : "02Bp5yXsQVO2BlUgYViYvt",</span><br><span class="line">              "allow_primary" : true</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        ]</span><br><span class="line">   &#125;'</span><br></pre></td></tr></table></figure><p>其中，index代表索引名称；shard代表shard分片序号；node代表的是集群或节点唯一标识</p><h5 id="再次验证集群"><a href="#再次验证集群" class="headerlink" title="再次验证集群"></a>再次验证集群</h5><p>待我们手动循环执行以上脚本，处理未注册的shard信息后，再次验证集群的状态，同样输入命令”curl -XGET ‘<a href="http://server_ip:9200/_cluster/health?pretty&#39;&quot;,查看集群状态，可以看到集群状态已经为green了。" target="_blank" rel="noopener">http://server_ip:9200/_cluster/health?pretty&#39;&quot;,查看集群状态，可以看到集群状态已经为green了。</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -XGET 'http://server_ip:9200/_cluster/health?pretty'</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  "cluster_name" : "cluster",</span><br><span class="line">  "status" : "green",       #集群状态green   </span><br><span class="line">  "timed_out" : false,</span><br><span class="line">  "number_of_nodes" : 8,</span><br><span class="line">  "number_of_data_nodes" : 8,</span><br><span class="line">  "active_primary_shards" : 12101,</span><br><span class="line">  "active_shards" : 24202,</span><br><span class="line">  "relocating_shards" : 2,</span><br><span class="line">  "initializing_shards" : 0,</span><br><span class="line">  "unassigned_shards" : 0,       #未注册的分片已经成了0</span><br><span class="line">  "delayed_unassigned_shards" : 0,</span><br><span class="line">  "number_of_pending_tasks" : 2030465,</span><br><span class="line">  "number_of_in_flight_fetch" : 0,</span><br><span class="line">  "task_max_waiting_in_queue_millis" : 2880496,</span><br><span class="line">  "active_shards_percent_as_number" : 100.0</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;当ES集群出现red或yellow状态的时候，出现大量的UNASSIGNED未注册分片解决方案&lt;/p&gt;
&lt;h5 id=&quot;确保集群正常&quot;&gt;&lt;a href=&quot;#确保集群正常&quot; class=&quot;headerlink&quot; title=&quot;确保集群正常&quot;&gt;&lt;/a&gt;确保集群正常&lt;/h5&gt;&lt;ul&gt;
&lt;li&gt;服务正常启动&lt;/li&gt;
&lt;li&gt;9200端口正常监听&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="高级运维" scheme="https://garywu520.github.io/blog/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"/>
    
      <category term="elasticsearch" scheme="https://garywu520.github.io/blog/tags/elasticsearch/"/>
    
      <category term="ES" scheme="https://garywu520.github.io/blog/tags/ES/"/>
    
      <category term="ES分片" scheme="https://garywu520.github.io/blog/tags/ES%E5%88%86%E7%89%87/"/>
    
      <category term="shards" scheme="https://garywu520.github.io/blog/tags/shards/"/>
    
      <category term="unassigned shards" scheme="https://garywu520.github.io/blog/tags/unassigned-shards/"/>
    
  </entry>
  
  <entry>
    <title>linux通用系统备份与恢复</title>
    <link href="https://garywu520.github.io/blog/2019/04/10/linux%E9%80%9A%E7%94%A8%E7%B3%BB%E7%BB%9F%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/"/>
    <id>https://garywu520.github.io/blog/2019/04/10/linux通用系统备份与恢复/</id>
    <published>2019-04-10T09:38:11.000Z</published>
    <updated>2019-04-17T00:12:14.109Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>适用场景</p></blockquote><p>Linux系统备份与恢复使用dd命令将整块磁盘拷贝与恢复就可以快速的启动操作系统。但有个问题是：如果之前的磁盘有逻辑坏道怎么办？这样一来，dd恢复后的操作系统也大几率存在逻辑坏道的问题。</p><p>基于此，本文章详细介绍如何使用tar来备份与还原系统。</p><h4 id="准备环境"><a href="#准备环境" class="headerlink" title="准备环境"></a>准备环境</h4><ul><li><p><strong>boot分区为独立分区</strong></p><p>这里备份恢复的系统所使用的boot分区，均为独立分区，大小200M</p></li><li><p><strong>对应linux发行版的livecd</strong></p><p>这里是Gentoo系统，故这里下载 install-amd64-minimal-20170302.iso</p></li><li><p><strong>移动硬盘</strong></p><p>tar压缩后，将压缩文件放到移动硬盘中</p></li></ul><a id="more"></a><h4 id="备份linux系统"><a href="#备份linux系统" class="headerlink" title="备份linux系统"></a>备份linux系统</h4><h5 id="1-启动livecd系统"><a href="#1-启动livecd系统" class="headerlink" title="1. 启动livecd系统"></a>1. 启动livecd系统</h5><h5 id="2-查看硬盘分区情况，确定要备份的分区，这里是sda1"><a href="#2-查看硬盘分区情况，确定要备份的分区，这里是sda1" class="headerlink" title="2. 查看硬盘分区情况，确定要备份的分区，这里是sda1"></a>2. 查看硬盘分区情况，确定要备份的分区，这里是sda1</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fdisk -l  /dev/sda</span><br></pre></td></tr></table></figure><h5 id="3-挂载sda1和boot分区"><a href="#3-挂载sda1和boot分区" class="headerlink" title="3. 挂载sda1和boot分区"></a>3. 挂载sda1和boot分区</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mkdir /mnt/sda3 /mnt/boot</span><br><span class="line">mount /dev/sda1  /mnt/boot</span><br><span class="line">mount /dev/sda3  /mnt/sda3</span><br><span class="line">cd /mnt/boot &amp;&amp; ls</span><br><span class="line">cd /mnt/sda3 &amp;&amp; ls</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">查看要备份的系统根目录，如果有其他的分区需要挂载备份，同理挂载即可。</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mkdir /mnt/sdc</span><br><span class="line">mount /dev/sdc /mnt/sdc</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">挂载准备的移动硬盘</span></span><br></pre></td></tr></table></figure><h5 id="4-打包备份"><a href="#4-打包备份" class="headerlink" title="4. 打包备份"></a>4. 打包备份</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd /mnt/sda3</span><br><span class="line">tar cvpfz /mnt/sdc/backup.tgz ./  </span><br><span class="line">du -sh /mnt/sdc/backup.tgz</span><br><span class="line"></span><br><span class="line">cd /mnt/boot</span><br><span class="line">tar cvpfz /mnt/sdc/boot.tgz ./</span><br><span class="line">du -sh tar cvpfz /mnt/sdc/boot.tgz</span><br></pre></td></tr></table></figure><p>cvpfz 意思是“创建档案文件”、保留所有东西原来的权限以及使用gzip来减小文件尺寸。<br>打包后放到移动硬盘的/mnt/sdc1目录,  使用du命令来查看大小。</p><h5 id="5-卸载掉移动硬盘挂载"><a href="#5-卸载掉移动硬盘挂载" class="headerlink" title="5. 卸载掉移动硬盘挂载"></a>5. 卸载掉移动硬盘挂载</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">umount /mnt/sdc</span><br></pre></td></tr></table></figure><h4 id="linux系统还原"><a href="#linux系统还原" class="headerlink" title="linux系统还原"></a>linux系统还原</h4><p>现在就可以拿着移动硬盘的tgz压缩的系统，去还原到其他机器了</p><h5 id="1-启动livecd"><a href="#1-启动livecd" class="headerlink" title="1. 启动livecd"></a>1. 启动livecd</h5><h5 id="2-给新服务器分区并格式化"><a href="#2-给新服务器分区并格式化" class="headerlink" title="2. 给新服务器分区并格式化"></a>2. 给新服务器分区并格式化</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 这里使用fdisk给系统分区，注:第一个分区应预留2048k的空间</span></span><br><span class="line">fdisk /dev/sda</span><br><span class="line">o #初始化dos格式</span><br><span class="line">p #查看分区</span><br><span class="line">n #创建分区</span><br><span class="line">  p #创建主分区</span><br><span class="line">  2048  +200M   #创建独立boot分区</span><br><span class="line">  ...   +8G     #创建swap分区</span><br><span class="line">  ...   +50G    #创建根分区</span><br><span class="line">  ...   ...     #剩余给数据分区</span><br><span class="line">最后输入w保存分区</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">格式化分区</span></span><br><span class="line">mkfs.reiserfs              #格式化boot分区</span><br><span class="line">mkswap /dev/sda2           #格式化swap</span><br><span class="line">mkfs.reiserfs /dev/sda3    #格式化根分区</span><br><span class="line">mkfs.reiserfs /dev/sda4    #格式化数据分区</span><br></pre></td></tr></table></figure><h5 id="3-挂载分区"><a href="#3-挂载分区" class="headerlink" title="3. 挂载分区"></a>3. 挂载分区</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /mnt/sda1 /mnt/sda3 /mnt/sdbc </span><br><span class="line">mount /dev/sda1 /mnt/sda1 #临时挂载boot分区，用于恢复数据文件</span><br><span class="line">mount /dev/sda3 /mnt/sda3  #挂载根分区</span><br><span class="line">mount /dev/sdc /mnt/sdc  #挂载移动硬盘</span><br></pre></td></tr></table></figure><p><strong>4.解压tar包</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar xvpfz /mnt/sdc/backup.tgz -C /mnt/sda3  #解压备份文件到根分区</span><br><span class="line">tar xvpfz /mnt/sdc/boot.tgz -C /mnt/sda1  #解压boot文件到boot分区</span><br></pre></td></tr></table></figure><p><strong>5.重新挂载boot分区，安装grub到mbr</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd /mnt/sda3/boot/ #查看此目录是否有文件，有的话临时移走</span><br><span class="line">umount /mnt/sda1 #卸载boot分区挂载</span><br><span class="line">mount /dev/sda1 /mnt/sda3/boot  </span><br><span class="line"><span class="meta">#</span><span class="bash">注意：重新把boot分区挂载到系统下的boot目录，这是chroot安装grub时的默认位置.即: /boot</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">chroot /dev/sda3   #chroot到根分区</span><br><span class="line">grub2-install /dev/sda    #安装引导</span><br><span class="line">grub2-mkconfig -o /boot/grub/grub.cfg  #重新生成配置文件</span><br></pre></td></tr></table></figure><h5 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h5><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">如果系统版本较老，可能使用的是grub-<span class="keyword">install</span>，而非grub2-<span class="keyword">install</span>,故需要使用如下方法安装引导</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">chroot /dev/sda3  #chroot到根分区</span><br><span class="line">df -h</span><br><span class="line">mount /dev/sda1 /boot  #chroot后挂载/dev/sda1分区到/boot</span><br><span class="line">grub-install /dev/sda  #安装引导</span><br></pre></td></tr></table></figure><h5 id="6-修改fatab和grub"><a href="#6-修改fatab和grub" class="headerlink" title="6. 修改fatab和grub"></a>6. 修改fatab和grub</h5><p><strong>修改fatab</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">将/etc/fstab文件，更正现有挂载信息</span><br></pre></td></tr></table></figure><p><strong>确认/boot/grub/grub.conf文件是否正确</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">cat /boot/grub/grub.conf</span><br><span class="line">default 0</span><br><span class="line">timeout 30</span><br><span class="line"></span><br><span class="line">title Gentoo Linux 3.5.7-gentoo</span><br><span class="line">root (hd0,0)</span><br><span class="line"><span class="meta">#</span><span class="bash">hd0,hd1,hd2,hd3对应sda,sdb,sdc,sdd依此类推</span></span><br><span class="line">kernel /boot/kernel-genkernel-x86_64-3.5.7-gentoo root=/dev/sda3   </span><br><span class="line"><span class="meta">#</span><span class="bash">这里kernel路径要正确，并且root要与根分区对应</span></span><br><span class="line">initrd /boot/initramfs-genkernel-x86_64-3.5.7-gentoo</span><br></pre></td></tr></table></figure><p><strong>7.重启机器确认系统能正确引导</strong></p><h5 id="8-修复网络"><a href="#8-修复网络" class="headerlink" title="8. 修复网络"></a>8. 修复网络</h5><p>系统还原后，进入系统，发现网卡不能启动，原因是 /etc/udev/rules.d/70-persistent-net.rules文件在捣鬼，mv成其他名字，重启系统后，系统会自动生成此文件，这时候网卡就可以正常启动了。</p><p>如果还不能解决问题，需要检测下网卡模块是否已经加载：<br>lsmod |grep e1000</p><p>参考：<a href="https://wiki.gentoo.org/wiki/GRUB2/zh-cn#BIOS_.E5.BC.95.E5.AF.BC.EF.BC.8C.E4.BD.BF.E7.94.A8_MBR" target="_blank" rel="noopener">Gentoo Linux</a></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;适用场景&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Linux系统备份与恢复使用dd命令将整块磁盘拷贝与恢复就可以快速的启动操作系统。但有个问题是：如果之前的磁盘有逻辑坏道怎么办？这样一来，dd恢复后的操作系统也大几率存在逻辑坏道的问题。&lt;/p&gt;
&lt;p&gt;基于此，本文章详细介绍如何使用tar来备份与还原系统。&lt;/p&gt;
&lt;h4 id=&quot;准备环境&quot;&gt;&lt;a href=&quot;#准备环境&quot; class=&quot;headerlink&quot; title=&quot;准备环境&quot;&gt;&lt;/a&gt;准备环境&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;boot分区为独立分区&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这里备份恢复的系统所使用的boot分区，均为独立分区，大小200M&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;对应linux发行版的livecd&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这里是Gentoo系统，故这里下载 install-amd64-minimal-20170302.iso&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;移动硬盘&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;tar压缩后，将压缩文件放到移动硬盘中&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="高级运维" scheme="https://garywu520.github.io/blog/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"/>
    
      <category term="linux" scheme="https://garywu520.github.io/blog/tags/linux/"/>
    
      <category term="系统备份" scheme="https://garywu520.github.io/blog/tags/%E7%B3%BB%E7%BB%9F%E5%A4%87%E4%BB%BD/"/>
    
      <category term="系统恢复" scheme="https://garywu520.github.io/blog/tags/%E7%B3%BB%E7%BB%9F%E6%81%A2%E5%A4%8D/"/>
    
  </entry>
  
  <entry>
    <title>ESXI6.7-Path补丁在线升级</title>
    <link href="https://garywu520.github.io/blog/2019/04/03/ESXI6-7-Path%E8%A1%A5%E4%B8%81%E5%9C%A8%E7%BA%BF%E5%8D%87%E7%BA%A7/"/>
    <id>https://garywu520.github.io/blog/2019/04/03/ESXI6-7-Path补丁在线升级/</id>
    <published>2019-04-03T06:58:45.000Z</published>
    <updated>2019-04-03T09:54:53.985Z</updated>
    
    <content type="html"><![CDATA[<h5 id="查看当前ESXI6-7内部版本号"><a href="#查看当前ESXI6-7内部版本号" class="headerlink" title="查看当前ESXI6.7内部版本号"></a>查看当前ESXI6.7内部版本号</h5><p>VMware ESXI Web —-&gt; 帮助 —&gt; 关于 </p><p><img src="https://raw.githubusercontent.com/wuyanteng/wuyanteng.github.io/master/images/vmware_esxi_about.png" alt="ESXI-about"></p><a id="more"></a><h5 id="升级ESXI补丁"><a href="#升级ESXI补丁" class="headerlink" title="升级ESXI补丁"></a>升级ESXI补丁</h5><ul><li><p>Web UI启用SSH服务，并登录</p></li><li><p>ESXI6.7各内部版本升级列表：</p><ul><li><p><a href="https://esxi-patches.v-front.de/ESXi-6.5.0.html" target="_blank" rel="noopener">ESXI-6.5.0-Path补丁</a></p></li><li><p><a href="https://esxi-patches.v-front.de/ESXi-6.7.0.html" target="_blank" rel="noopener">ESXI-6.7.0-Path补丁</a></p></li></ul></li></ul><p>​       点击比当前版本号新的版本,如： <strong>ESXi-6.7.0-20180704001-standard</strong> 即可看到升级说明，如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Cut and paste these commands into an ESXi shell to update your host with this Imageprofile</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> See the Help page <span class="keyword">for</span> more instructions</span></span><br><span class="line"></span><br><span class="line"><span class="meta">shell&gt;</span><span class="bash"> esxcli network firewall ruleset <span class="built_in">set</span> -e <span class="literal">true</span> -r httpClient</span></span><br><span class="line"></span><br><span class="line"><span class="meta">shell&gt;</span><span class="bash"> esxcli software profile update -p ESXi-6.7.0-20180704001-standard \</span></span><br><span class="line">-d https://hostupdate.vmware.com/software/VUM/PRODUCTION/main/vmw-depot-index.xml</span><br><span class="line"></span><br><span class="line"><span class="meta">shell&gt;</span><span class="bash"> esxcli network firewall ruleset <span class="built_in">set</span> -e <span class="literal">false</span> -r httpClient</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Reboot to complete the upgrade</span></span><br></pre></td></tr></table></figure><p>照做就是了，最后需要重启ESXI物理服务器来完成最新更新。</p><blockquote><p>注：升级时，可以直接选择最新Build版本进行在线更新</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;h5 id=&quot;查看当前ESXI6-7内部版本号&quot;&gt;&lt;a href=&quot;#查看当前ESXI6-7内部版本号&quot; class=&quot;headerlink&quot; title=&quot;查看当前ESXI6.7内部版本号&quot;&gt;&lt;/a&gt;查看当前ESXI6.7内部版本号&lt;/h5&gt;&lt;p&gt;VMware ESXI Web —-&amp;gt; 帮助 —&amp;gt; 关于 &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/wuyanteng/wuyanteng.github.io/master/images/vmware_esxi_about.png&quot; alt=&quot;ESXI-about&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="高级运维" scheme="https://garywu520.github.io/blog/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"/>
    
      <category term="ESXI PATH" scheme="https://garywu520.github.io/blog/tags/ESXI-PATH/"/>
    
      <category term="ESXI补丁升级" scheme="https://garywu520.github.io/blog/tags/ESXI%E8%A1%A5%E4%B8%81%E5%8D%87%E7%BA%A7/"/>
    
      <category term="ESXI6.7" scheme="https://garywu520.github.io/blog/tags/ESXI6-7/"/>
    
  </entry>
  
  <entry>
    <title>binlog2sql之MySQL数据闪回实战</title>
    <link href="https://garywu520.github.io/blog/2019/04/03/binlog2sql%E4%B9%8BMySQL%E5%BF%AB%E9%80%9F%E6%81%A2%E5%A4%8D%E5%AE%9E%E6%88%98/"/>
    <id>https://garywu520.github.io/blog/2019/04/03/binlog2sql之MySQL快速恢复实战/</id>
    <published>2019-04-03T03:04:23.000Z</published>
    <updated>2019-04-04T07:36:13.465Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>MySQL闪回特性最早由阿里彭立勋开发，彭在2012年给官方提交了一个patch，并对<a href="http://www.penglixun.com/tech/database/mysql_flashback_feature.html" target="_blank" rel="noopener">闪回设计思路</a>做了说明。但是因为种种原因，业内安装这个patch的团队至今还是少数，真正应用到线上的更是少之又少。</p><p>而binlog2sql则是借鉴的这种思路，它由美团点评DBA团队(上海)出品，多次在线上环境做快速回滚。</p></blockquote><h5 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h5><p>某天，同事A误删了大批线上用户MySQL表的数据……</p><p>他急忙找到公司DBA请求帮助，“客服电话已被打爆，大量用户投诉无法登陆，领导非常恼火。请问多久能恢复数据？”DBA一脸懵逼，沉默十秒后，伸出一根手指。“你的意思是一分钟就能恢复？太好了。”小明终于有些放松，露出了一丝笑容。“不，我们中有个人将会离开公司……” DBA沉痛的说道。</p><p>参考：<a href="https://github.com/wuyanteng/binlog2sql/blob/master/example/mysql-flashback-priciple-and-practice.md" target="_blank" rel="noopener">GitHub MySQL闪回</a></p><a id="more"></a><h5 id="MySQL-binlog概述"><a href="#MySQL-binlog概述" class="headerlink" title="MySQL binlog概述"></a>MySQL binlog概述</h5><p>(1) MySQL binlog已event的形式，记录了MySQL Server从启用binlog以来所有的变更信息，能够帮助重现这之间的所有变化。</p><p>(2) MySQL 引入binlog主要有两个目的：</p><ul><li>为了主从复制</li><li>某些备份还原操作后需要重新应用binlog</li></ul><p>(3) binlog格式共分为3种，各有优缺点:</p><ul><li><p>statement: 基于SQL语句的模式，binlog数据量小，但是某些语句和函数在复制过程中可能导致数据不一致，甚至报错。</p></li><li><p>row: 基于行的模式，记录的是行的完整变化。很安全，但是binlog文件会比其他两种模式大很多。</p></li><li><p>mixed: 混合模式，根据语句来选用是statement还是row模式。</p></li></ul><h5 id="MySQL-binlog闪回原理"><a href="#MySQL-binlog闪回原理" class="headerlink" title="MySQL binlog闪回原理"></a>MySQL binlog闪回原理</h5><p><strong>利用binlog闪回，需要将binlog格式设置为row</strong></p><p>既然binlog以event的形式记录了所有变更的信息，那么我们需要回滚event事务，从后往前回滚即可。</p><h5 id="单个event的回滚原理"><a href="#单个event的回滚原理" class="headerlink" title="单个event的回滚原理"></a>单个event的回滚原理</h5><p>这里以表test.user来演示原理，同时需要使用binlog2sql将原始binlog转化成可读SQL</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show create table test.user\G</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">       Table: user</span><br><span class="line">Create Table: CREATE TABLE `user` (</span><br><span class="line">  `id` int(11) NOT NULL AUTO_INCREMENT,</span><br><span class="line">  `name` varchar(10) DEFAULT NULL,</span><br><span class="line">  PRIMARY KEY (`id`)</span><br><span class="line">) ENGINE=InnoDB AUTO_INCREMENT=6 DEFAULT CHARSET=utf8</span><br></pre></td></tr></table></figure><ul><li>对于delete操作，我们从binlog提取出delete信息，生成回滚语句的insert。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">原始：DELETE FROM `test`.`user` WHERE `id`=1 AND `name`=&apos;小赵&apos;;</span><br><span class="line">回滚：INSERT INTO `test`.`user`(`id`, `name`) VALUES (1, &apos;小赵&apos;);</span><br></pre></td></tr></table></figure><ul><li>对于insert操作，回滚SQL是delete</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">原始：INSERT INTO `test`.`user`(`id`, `name`) VALUES (2, &apos;小钱&apos;);</span><br><span class="line">回滚：DELETE FROM `test`.`user` WHERE `id`=2 AND `name`=&apos;小钱&apos;;</span><br></pre></td></tr></table></figure><ul><li>对于update操作，回滚SQL应该交换SET和WHERE的值</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">原始：UPDATE `test`.`user` SET `id`=3, `name`=&apos;小李&apos; WHERE `id`=3 AND `name`=&apos;小孙&apos;;</span><br><span class="line">回滚：UPDATE `test`.`user` SET `id`=3, `name`=&apos;小孙&apos; WHERE `id`=3 AND `name`=&apos;小李&apos;;</span><br></pre></td></tr></table></figure><h4 id="MySQL数据闪回实战"><a href="#MySQL数据闪回实战" class="headerlink" title="MySQL数据闪回实战"></a>MySQL数据闪回实战</h4><blockquote><p>真实的闪回场景中，最关键的是能快速筛选出真正需要回滚的SQL</p></blockquote><p>安装binlog2sql，参考：<a href="https://wuyanteng.github.io/2019/04/02/binlog%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7%E4%B9%8Bbinlog2sql/#more" target="_blank" rel="noopener">binlog分析工具之binlog2sql</a></p><h5 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h5><p>同事A，在11:44时误删了test库bigdata表的大批数据，需要紧急回滚。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#test库bigdata表原有数据</span><br><span class="line"></span><br><span class="line">mysql&gt; select * from bigdata;</span><br><span class="line">+----------+------------------+-------------+---------+---------------------+</span><br><span class="line">| class_id | class_name       | class_month | teacher | last_mod_ts         |</span><br><span class="line">+----------+------------------+------------+----------+---------------------+</span><br><span class="line">|        1 | bigdata intro.   |           8 | Mars    | 2019-04-04 10:41:42 |</span><br><span class="line">|        2 | hadoop intro.    |           8 | Mars    | 2019-04-04 10:41:42 |</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 同事A在下午2019-04-04 14:47左右删除了表中大部分数据，此时，正常业务数据是在继续写入的。</span><br><span class="line">mysql&gt; delete from bigdata where last_mod_ts &gt;&apos;2019-04-04 10:45:00&apos;;</span><br><span class="line">Query OK, 2 rows affected (0.07 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; select count(*) from bigdata;</span><br><span class="line">+----------+</span><br><span class="line">| count(*) |</span><br><span class="line">+----------+</span><br><span class="line">|       18 |</span><br><span class="line">+----------+</span><br><span class="line">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure><h5 id="恢复数据步骤"><a href="#恢复数据步骤" class="headerlink" title="恢复数据步骤"></a>恢复数据步骤</h5><ul><li><strong>登陆mysql，查看目前的binlog文件</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show master logs;</span><br><span class="line">+------------------+-----------+</span><br><span class="line">| Log_name         | File_size |</span><br><span class="line">+------------------+-----------+</span><br><span class="line">| mysql-bin.000001 |       177 |</span><br><span class="line">| mysql-bin.000002 |      6763 |</span><br><span class="line">+------------------+-----------+</span><br><span class="line">2 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure><p>可以看到，最新的binlog文件是 mysql-bin.000002。我们的目标是筛选出需要回滚的SQL。</p><p>由于同事A只知道大致误操作的时间，故首先根据时间做一次过滤，只需要解析test库bigdata表。</p><p>注：如果涉及多个sql误操作，则生成的binlog可能分布在多个文件，需解析多个文件</p><ul><li><strong>解析binlog为标准SQL</strong></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> python binlog2sql/binlog2sql.py -h127.0.0.1 -uroot -p -P3306 -dtest -tbigdata --start-file=<span class="string">'mysql-bin.000002'</span> --start-datetime=<span class="string">'2019-04-04 14:45:00'</span> --stop-datetime=<span class="string">'2019-04-04 14:50:00'</span> &gt;/tmp/raw.sql</span></span><br></pre></td></tr></table></figure><figure class="highlight n1ql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># cat /tmp/raw.sql </span><br><span class="line"></span><br><span class="line"><span class="keyword">DELETE</span> <span class="keyword">FROM</span> <span class="symbol">`test`</span>.<span class="symbol">`bigdata`</span> <span class="keyword">WHERE</span> <span class="symbol">`class_id`</span>=<span class="number">19</span> <span class="keyword">AND</span> <span class="symbol">`class_name`</span>=<span class="string">'Other'</span> <span class="keyword">AND</span> <span class="symbol">`class_month`</span>=<span class="number">1704</span> <span class="keyword">AND</span> <span class="symbol">`teacher`</span>=<span class="string">'GaryWu'</span> <span class="keyword">AND</span> <span class="symbol">`last_mod_ts`</span>=<span class="string">'2019-04-04 10:52:10'</span> <span class="keyword">LIMIT</span> <span class="number">1</span>; #start 6438 end 6732 time 2019-04-04 14:47:43</span><br><span class="line"></span><br><span class="line"><span class="keyword">DELETE</span> <span class="keyword">FROM</span> <span class="symbol">`test`</span>.<span class="symbol">`bigdata`</span> <span class="keyword">WHERE</span> <span class="symbol">`class_id`</span>=<span class="number">20</span> <span class="keyword">AND</span> <span class="symbol">`class_name`</span>=<span class="string">'Other'</span> <span class="keyword">AND</span> <span class="symbol">`class_month`</span>=<span class="number">1705</span> <span class="keyword">AND</span> <span class="symbol">`teacher`</span>=<span class="string">'wuyanteng'</span> <span class="keyword">AND</span> <span class="symbol">`last_mod_ts`</span>=<span class="string">'2019-04-04 10:52:25'</span> <span class="keyword">LIMIT</span> <span class="number">1</span>; #start 6438 end 6732 time 2019-04-04 14:47:43</span><br></pre></td></tr></table></figure><p>根据位置信息，我们确定了误操作sql来自同一个事务，准确位置在6438-6732之间（binlog2sql对于同一个事务会输出同样的start position）。</p><ul><li><strong>使用 -B 选项生成回滚SQL，并检查回滚SQL是否正确</strong></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> python binlog2sql/binlog2sql.py -h127.0.0.1 -uroot -p -P3306 -dtest -tbigdata --start-file=<span class="string">'mysql-bin.000002'</span> --start-datetime=<span class="string">'2019-04-04 14:45:00'</span> --stop-datetime=<span class="string">'2019-04-04 14:50:00'</span> -B &gt;/tmp/rollback.sql</span></span><br></pre></td></tr></table></figure><p>解析出的回滚SQL经常会需要进一步筛选并且需要与业务方确认SQL语句是否存在问题。</p><figure class="highlight n1ql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># cat /tmp/rollback.sql</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="symbol">`test`</span>.<span class="symbol">`bigdata`</span>(<span class="symbol">`class_id`</span>, <span class="symbol">`class_name`</span>, <span class="symbol">`class_month`</span>, <span class="symbol">`teacher`</span>, <span class="symbol">`last_mod_ts`</span>) <span class="keyword">VALUES</span> (<span class="number">20</span>, <span class="string">'Other'</span>, <span class="number">1705</span>, <span class="string">'wuyanteng'</span>, <span class="string">'2019-04-04 10:52:25'</span>); #start 6438 end 6732 time 2019-04-04 14:47:43</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="symbol">`test`</span>.<span class="symbol">`bigdata`</span>(<span class="symbol">`class_id`</span>, <span class="symbol">`class_name`</span>, <span class="symbol">`class_month`</span>, <span class="symbol">`teacher`</span>, <span class="symbol">`last_mod_ts`</span>) <span class="keyword">VALUES</span> (<span class="number">19</span>, <span class="string">'Other'</span>, <span class="number">1704</span>, <span class="string">'GaryWu'</span>, <span class="string">'2019-04-04 10:52:10'</span>); #start 6438 end 6732 time 2019-04-04 14:47:43</span><br></pre></td></tr></table></figure><ul><li><strong>如果一切准确无误，则执行回滚语句</strong></li></ul><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">mysql -h127.0.0.1 -P3306 -uroot -p &lt; /tmp/rollback.sql</span><br><span class="line"></span><br><span class="line">mysql&gt; select count(<span class="strong">*) from bigdata;</span></span><br><span class="line"><span class="strong">+----------+</span></span><br><span class="line"><span class="strong">| count(*</span>) |</span><br><span class="line"><span class="code">+----------+</span></span><br><span class="line">|       20 |</span><br><span class="line"><span class="code">+----------+</span></span><br><span class="line">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure><h5 id="MySQL闪回思想"><a href="#MySQL闪回思想" class="headerlink" title="MySQL闪回思想"></a>MySQL闪回思想</h5><ul><li>闪回的目标：快速筛选出真正需要回滚的数据。</li><li>先根据库、表、时间做一次过滤，再根据位置做更准确的过滤。</li><li>由于数据一直在写入，要确保回滚sql中不包含其他数据。可根据是否是同一事务、误操作行数、字段值的特征等等来帮助判断。</li><li>执行回滚sql时如有报错，需要查实具体原因，一般是因为对应的数据已发生变化。由于是严格的行模式，只要有唯一键(包括主键)存在，就只会报某条数据不存在的错，不必担心会更新不该操作的数据。业务如果有特殊逻辑，数据回滚可能会带来影响。</li><li>如果只回滚某张表，并且该表有关联表，关联表并不会被回滚，需与业务方沟通清楚。</li></ul><p><strong>总之，哪些数据需要回滚，让业务方来判断！</strong></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;MySQL闪回特性最早由阿里彭立勋开发，彭在2012年给官方提交了一个patch，并对&lt;a href=&quot;http://www.penglixun.com/tech/database/mysql_flashback_feature.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;闪回设计思路&lt;/a&gt;做了说明。但是因为种种原因，业内安装这个patch的团队至今还是少数，真正应用到线上的更是少之又少。&lt;/p&gt;
&lt;p&gt;而binlog2sql则是借鉴的这种思路，它由美团点评DBA团队(上海)出品，多次在线上环境做快速回滚。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h5 id=&quot;适用场景&quot;&gt;&lt;a href=&quot;#适用场景&quot; class=&quot;headerlink&quot; title=&quot;适用场景&quot;&gt;&lt;/a&gt;适用场景&lt;/h5&gt;&lt;p&gt;某天，同事A误删了大批线上用户MySQL表的数据……&lt;/p&gt;
&lt;p&gt;他急忙找到公司DBA请求帮助，“客服电话已被打爆，大量用户投诉无法登陆，领导非常恼火。请问多久能恢复数据？”DBA一脸懵逼，沉默十秒后，伸出一根手指。“你的意思是一分钟就能恢复？太好了。”小明终于有些放松，露出了一丝笑容。“不，我们中有个人将会离开公司……” DBA沉痛的说道。&lt;/p&gt;
&lt;p&gt;参考：&lt;a href=&quot;https://github.com/wuyanteng/binlog2sql/blob/master/example/mysql-flashback-priciple-and-practice.md&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;GitHub MySQL闪回&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="高级运维" scheme="https://garywu520.github.io/blog/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"/>
    
      <category term="binlog" scheme="https://garywu520.github.io/blog/tags/binlog/"/>
    
      <category term="mysql" scheme="https://garywu520.github.io/blog/tags/mysql/"/>
    
      <category term="binlog2sql" scheme="https://garywu520.github.io/blog/tags/binlog2sql/"/>
    
      <category term="row" scheme="https://garywu520.github.io/blog/tags/row/"/>
    
      <category term="数据闪回" scheme="https://garywu520.github.io/blog/tags/%E6%95%B0%E6%8D%AE%E9%97%AA%E5%9B%9E/"/>
    
  </entry>
  
  <entry>
    <title>binlog分析工具之binlog2sql</title>
    <link href="https://garywu520.github.io/blog/2019/04/02/binlog%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7%E4%B9%8Bbinlog2sql/"/>
    <id>https://garywu520.github.io/blog/2019/04/02/binlog分析工具之binlog2sql/</id>
    <published>2019-04-02T02:36:22.000Z</published>
    <updated>2019-04-02T03:02:36.679Z</updated>
    
    <content type="html"><![CDATA[<p>GitHub项目地址：<a href="https://github.com/danfengcao/binlog2sql" target="_blank" rel="noopener">binlog2sql</a></p><h5 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h5><ul><li>从binlog生成标准SQL, 用于分析</li><li>数据快速回滚</li></ul><h5 id="已测试的环境"><a href="#已测试的环境" class="headerlink" title="已测试的环境"></a>已测试的环境</h5><ul><li>Python 2.7 或 3.4+</li><li>MySQL 5.6 或 5.7</li></ul><h5 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h5><p>python3安装参考–自带pip：<a href="https://wuyanteng.github.io/2018/11/23/%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85Python3%E5%8F%8A%E6%89%A9%E5%B1%95/" target="_blank" rel="noopener">编译安装Python3及扩展</a></p><p>git安装：略</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">shell&gt;</span><span class="bash"> git <span class="built_in">clone</span> https://github.com/danfengcao/binlog2sql.git &amp;&amp; <span class="built_in">cd</span> binlog2sql</span></span><br><span class="line"><span class="meta">shell&gt;</span><span class="bash"> pip install -r requirements.txt</span></span><br></pre></td></tr></table></figure><a id="more"></a><h5 id="MySQL使用要求"><a href="#MySQL使用要求" class="headerlink" title="MySQL使用要求"></a>MySQL使用要求</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[mysqld]</span><br><span class="line">server_id = 1       #需配置server_id参数</span><br><span class="line">log_bin = /var/log/mysql/mysql-bin.log</span><br><span class="line">max_binlog_size = 1G</span><br><span class="line">binlog_format = row</span><br><span class="line">binlog_row_image = full  #默认为FULL</span><br></pre></td></tr></table></figure><h5 id="用户权限要求"><a href="#用户权限要求" class="headerlink" title="用户权限要求"></a>用户权限要求</h5><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">建议授权</span><br><span class="line">GRANT SELECT, REPLICATION SLAVE, REPLICATION<span class="built_in"> CLIENT </span>ON *.* <span class="keyword">TO</span></span><br></pre></td></tr></table></figure><h5 id="基本用法-解析出标准SQL"><a href="#基本用法-解析出标准SQL" class="headerlink" title="基本用法: 解析出标准SQL"></a>基本用法: 解析出标准SQL</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">格式：</span><br><span class="line"><span class="meta">shell&gt;</span><span class="bash"> python binlog2sql.py -h127.0.0.1 -P3306 -uadmin -p<span class="string">'admin'</span> -dtestdb -t test3 test4 --start-file=<span class="string">'mysql-bin.000002'</span> &gt;&gt;/data/testdb_binlog2sql.sql</span></span><br></pre></td></tr></table></figure><h5 id="选项"><a href="#选项" class="headerlink" title="选项"></a>选项</h5><p>– <strong>mysql连接配置</strong></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-h host;   -P<span class="built_in"> port; </span>  -u<span class="built_in"> user; </span>  -p password</span><br></pre></td></tr></table></figure><p>– <strong>解析模式</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">--stop-never 持续解析binlog。可选。默认False，同步至执行命令时最新的binlog位置。</span><br><span class="line"></span><br><span class="line">-K, --no-primary-key 对INSERT语句去除主键。可选。默认False</span><br><span class="line"></span><br><span class="line">-B, --flashback 生成回滚SQL，可解析大文件，不受内存限制。可选。默认False。与stop-never或no-primary-key不能同时添加。</span><br><span class="line"></span><br><span class="line">--back-interval -B模式下，每打印一千行回滚SQL，加一句SLEEP多少秒，如不想加SLEEP，请设为0。可选。默认1.0。</span><br></pre></td></tr></table></figure><p>–  <strong>解析范围控制</strong></p><figure class="highlight fortran"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">--start-<span class="keyword">file</span> 起始解析文件，只需文件名，无需全路径 。必须。</span><br><span class="line"></span><br><span class="line">--start-<span class="keyword">position</span>/--start-pos 起始解析位置。可选。默认为start-<span class="keyword">file</span>的起始位置。</span><br><span class="line"></span><br><span class="line">--<span class="keyword">stop</span>-<span class="keyword">file</span>/--<span class="keyword">end</span>-<span class="keyword">file</span> 终止解析文件。可选。默认为start-<span class="keyword">file</span>同一个文件。若解析模式为<span class="keyword">stop</span>-never，此选项失效。</span><br><span class="line"></span><br><span class="line">--<span class="keyword">stop</span>-<span class="keyword">position</span>/--<span class="keyword">end</span>-pos 终止解析位置。可选。默认为<span class="keyword">stop</span>-<span class="keyword">file</span>的最末位置；若解析模式为<span class="keyword">stop</span>-never，此选项失效。</span><br><span class="line"></span><br><span class="line">--start-datetime 起始解析时间，格式<span class="string">'%Y-%m-%d %H:%M:%S'</span>。可选。默认不过滤。</span><br><span class="line"></span><br><span class="line">--<span class="keyword">stop</span>-datetime 终止解析时间，格式<span class="string">'%Y-%m-%d %H:%M:%S'</span>。可选。默认不过滤。</span><br></pre></td></tr></table></figure><p>– <strong>对象过滤</strong></p><figure class="highlight n1ql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">d, --databases 只解析目标db的sql，多个库用空格隔开，如-d db1 db2。可选。默认为空。</span><br><span class="line"></span><br><span class="line">-t, --tables 只解析目标table的sql，多张表用空格隔开，如-t tbl1 tbl2。可选。默认为空。</span><br><span class="line"></span><br><span class="line">--only-dml 只解析dml，忽略ddl。可选。默认False。</span><br><span class="line"></span><br><span class="line">--sql-type 只解析指定类型，支持<span class="keyword">INSERT</span>, <span class="keyword">UPDATE</span>, <span class="keyword">DELETE</span>。多个类型用空格隔开，如--sql-<span class="built_in">type</span> <span class="keyword">INSERT</span> <span class="keyword">DELETE</span>。可选。默认为增删改都解析。用了此参数但没填任何类型，则三者都不解析。</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;GitHub项目地址：&lt;a href=&quot;https://github.com/danfengcao/binlog2sql&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;binlog2sql&lt;/a&gt;&lt;/p&gt;
&lt;h5 id=&quot;适用场景&quot;&gt;&lt;a href=&quot;#适用场景&quot; class=&quot;headerlink&quot; title=&quot;适用场景&quot;&gt;&lt;/a&gt;适用场景&lt;/h5&gt;&lt;ul&gt;
&lt;li&gt;从binlog生成标准SQL, 用于分析&lt;/li&gt;
&lt;li&gt;数据快速回滚&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&quot;已测试的环境&quot;&gt;&lt;a href=&quot;#已测试的环境&quot; class=&quot;headerlink&quot; title=&quot;已测试的环境&quot;&gt;&lt;/a&gt;已测试的环境&lt;/h5&gt;&lt;ul&gt;
&lt;li&gt;Python 2.7 或 3.4+&lt;/li&gt;
&lt;li&gt;MySQL 5.6 或 5.7&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&quot;安装&quot;&gt;&lt;a href=&quot;#安装&quot; class=&quot;headerlink&quot; title=&quot;安装&quot;&gt;&lt;/a&gt;安装&lt;/h5&gt;&lt;p&gt;python3安装参考–自带pip：&lt;a href=&quot;https://wuyanteng.github.io/2018/11/23/%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85Python3%E5%8F%8A%E6%89%A9%E5%B1%95/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;编译安装Python3及扩展&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;git安装：略&lt;/p&gt;
&lt;figure class=&quot;highlight shell&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;meta&quot;&gt;shell&amp;gt;&lt;/span&gt;&lt;span class=&quot;bash&quot;&gt; git &lt;span class=&quot;built_in&quot;&gt;clone&lt;/span&gt; https://github.com/danfengcao/binlog2sql.git &amp;amp;&amp;amp; &lt;span class=&quot;built_in&quot;&gt;cd&lt;/span&gt; binlog2sql&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;meta&quot;&gt;shell&amp;gt;&lt;/span&gt;&lt;span class=&quot;bash&quot;&gt; pip install -r requirements.txt&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="高级运维" scheme="https://garywu520.github.io/blog/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"/>
    
      <category term="binlog" scheme="https://garywu520.github.io/blog/tags/binlog/"/>
    
      <category term="mysql" scheme="https://garywu520.github.io/blog/tags/mysql/"/>
    
      <category term="binlog2sql" scheme="https://garywu520.github.io/blog/tags/binlog2sql/"/>
    
      <category term="python" scheme="https://garywu520.github.io/blog/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>HDFS的Block数据balancer重新分布</title>
    <link href="https://garywu520.github.io/blog/2019/04/01/HDFS%E7%9A%84Block%E6%95%B0%E6%8D%AEbalancer%E9%87%8D%E6%96%B0%E5%88%86%E5%B8%83/"/>
    <id>https://garywu520.github.io/blog/2019/04/01/HDFS的Block数据balancer重新分布/</id>
    <published>2019-04-01T02:58:45.000Z</published>
    <updated>2019-04-01T03:13:50.104Z</updated>
    
    <content type="html"><![CDATA[<p>HDFS balancer重新平衡，即实现HDFS Block数据物理存储重新分布，可以有效解决物理磁盘空间占用高的问题。</p><p>在CDH HDFS集群中，务必至少有1个节点为balancer节点，否则CM平台将无“重新平衡”选项。如果集群中无balancer节点，则需要新增balancer角色。另外，balancer节点应运行在非namenode节点上</p><p>CM平台的“重新平衡” 实际上调用的是hadoop重平衡命令，即：hadoop balancer -threshold 5</p><p>参数注释：其中-threshold参数是用来判断数据平衡的依据，值范围为0-100。默认值为10，表示HDFS达到平衡状态的磁盘使用率偏差值为10%，如果机器与机器之间磁盘使用率偏差小于10%，那么我们就认为HDFS集群已经达到了平衡的状态。</p><p>注：Balancer阈值越高，需要平衡的量越少，DN占用率不够均衡；阈值越低，需要平衡的量越大， DN占有率越均衡；</p><a id="more"></a><h5 id="CM平台中重新平衡阈值设定"><a href="#CM平台中重新平衡阈值设定" class="headerlink" title="CM平台中重新平衡阈值设定"></a>CM平台中重新平衡阈值设定</h5><p><img src="https://raw.githubusercontent.com/wuyanteng/wuyanteng.github.io/master/images/cm%20hdfs%E9%87%8D%E6%96%B0%E5%B9%B3%E8%A1%A1.png" alt="cm重平衡"></p><p>判断集群是否平衡的目标参数，每一个 Datanode 存储使用率和集群总存储使用率的差值都应该小于这个阀值，理论上，该参数设置的越小，整个集群就越平衡，但是在线上环境中，Hadoop集群在进行balance时，还在并发的进行数据的写入和删除，所以有可能无法到达设定的平衡参数值。</p><h5 id="balancer命令帮助"><a href="#balancer命令帮助" class="headerlink" title="balancer命令帮助"></a>balancer命令帮助</h5><p>查看帮助：hadoop balancer -help</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop ~]# hadoop balancer -help</span><br><span class="line">DEPRECATED: Use of this script to execute hdfs command is deprecated.</span><br><span class="line">Instead use the hdfs command for it.</span><br><span class="line"></span><br><span class="line">Usage: java Balancer</span><br><span class="line">[-policy &lt;policy&gt;] the balancing policy: datanode or blockpool</span><br><span class="line">[-threshold &lt;threshold&gt;] Percentage of disk capacity</span><br><span class="line">[-exclude [-f &lt;hosts-file&gt; | comma-sperated list of hosts]] Excludes the specified datanodes.</span><br><span class="line">[-include [-f &lt;hosts-file&gt; | comma-sperated list of hosts]] Includes only the specified datanodes.</span><br><span class="line"></span><br><span class="line">Generic options supported are</span><br><span class="line">-conf &lt;configuration file&gt; specify an application configuration file</span><br><span class="line">-D &lt;property=value&gt; use value for given property</span><br><span class="line">-fs &lt;local|namenode:port&gt; specify a namenode</span><br><span class="line">-jt &lt;local|resourcemanager:port&gt; specify a ResourceManager</span><br><span class="line">-files &lt;comma separated list of files&gt; specify comma separated files to be copied to the map reduce cluster</span><br><span class="line">-libjars &lt;comma separated list of jars&gt; specify comma separated jar files to include in the classpath.</span><br><span class="line">-archives &lt;comma separated list of archives&gt; specify comma separated archives to be unarchived on the compute machines.</span><br><span class="line"></span><br><span class="line">The general command line syntax is</span><br><span class="line">bin/hadoop command [genericOptions] [commandOptions]</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;HDFS balancer重新平衡，即实现HDFS Block数据物理存储重新分布，可以有效解决物理磁盘空间占用高的问题。&lt;/p&gt;
&lt;p&gt;在CDH HDFS集群中，务必至少有1个节点为balancer节点，否则CM平台将无“重新平衡”选项。如果集群中无balancer节点，则需要新增balancer角色。另外，balancer节点应运行在非namenode节点上&lt;/p&gt;
&lt;p&gt;CM平台的“重新平衡” 实际上调用的是hadoop重平衡命令，即：hadoop balancer -threshold 5&lt;/p&gt;
&lt;p&gt;参数注释：其中-threshold参数是用来判断数据平衡的依据，值范围为0-100。默认值为10，表示HDFS达到平衡状态的磁盘使用率偏差值为10%，如果机器与机器之间磁盘使用率偏差小于10%，那么我们就认为HDFS集群已经达到了平衡的状态。&lt;/p&gt;
&lt;p&gt;注：Balancer阈值越高，需要平衡的量越少，DN占用率不够均衡；阈值越低，需要平衡的量越大， DN占有率越均衡；&lt;/p&gt;
    
    </summary>
    
    
      <category term="高级运维" scheme="https://garywu520.github.io/blog/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"/>
    
      <category term="CDH" scheme="https://garywu520.github.io/blog/tags/CDH/"/>
    
      <category term="大数据" scheme="https://garywu520.github.io/blog/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="hadoop" scheme="https://garywu520.github.io/blog/tags/hadoop/"/>
    
      <category term="HDFS" scheme="https://garywu520.github.io/blog/tags/HDFS/"/>
    
      <category term="CM" scheme="https://garywu520.github.io/blog/tags/CM/"/>
    
      <category term="balancer" scheme="https://garywu520.github.io/blog/tags/balancer/"/>
    
      <category term="重新平衡" scheme="https://garywu520.github.io/blog/tags/%E9%87%8D%E6%96%B0%E5%B9%B3%E8%A1%A1/"/>
    
      <category term="重新分布" scheme="https://garywu520.github.io/blog/tags/%E9%87%8D%E6%96%B0%E5%88%86%E5%B8%83/"/>
    
  </entry>
  
  <entry>
    <title>Mars-Hadoop Hive环境搭建</title>
    <link href="https://garywu520.github.io/blog/2019/03/27/Mars-Hadoop-Hive%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    <id>https://garywu520.github.io/blog/2019/03/27/Mars-Hadoop-Hive环境搭建/</id>
    <published>2019-03-27T06:07:43.000Z</published>
    <updated>2019-03-27T10:44:49.659Z</updated>
    
    <content type="html"><![CDATA[<h5 id="Hive连接模式"><a href="#Hive连接模式" class="headerlink" title="Hive连接模式"></a>Hive连接模式</h5><ul><li>单用户模式(元数据默认使用Derby关系型数据库存储)</li><li>多用户模式</li><li>远程模式</li></ul><h5 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h5><ul><li><p>Hadoop V2.7.2</p><p>要保证Hadoop服务已经启动。Hadoop环境搭建: <a href="https://wuyanteng.github.io/2018/12/19/Hadoop%20HA%202.7.3%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2-%E7%BB%88%E6%9E%81%E7%89%88/" target="_blank" rel="noopener">参考</a></p></li><li><p>MySQL主从</p><p>本次MySQL数据库部署在Slave1【IP:10.0.10.111】服务器上。</p></li><li><p>Hive 安装在Slave3【IP：10.0.10.113】上</p></li></ul><a id="more"></a><h5 id="下载Hive"><a href="#下载Hive" class="headerlink" title="下载Hive"></a>下载Hive</h5><p>官方网站：<a href="http://hive.apache.org/downloads.html" target="_blank" rel="noopener">http://hive.apache.org/downloads.html</a></p><p>下载带有*-bin的hive压缩包:  apache-hive-2.3.4-bin.tar.gz</p><h5 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tar -zxf apache-hive-2.3.4-bin.tar.gz</span><br><span class="line">mv apache-hive-2.3.4-bin /opt/</span><br><span class="line">ln -sv /opt/apache-hive-2.3.4-bin /opt/hive</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cat /etc/profile</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">Hive</span></span><br><span class="line">export HIVE_HOME=/opt/hive</span><br><span class="line">export PATH=$PATH:$HIVE_HOME/bin</span><br></pre></td></tr></table></figure><h4 id="配置Hive"><a href="#配置Hive" class="headerlink" title="配置Hive"></a>配置Hive</h4><p>(1) hive-env.sh</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cp /opt/hive/conf/hive-env.sh.template /opt/hive/conf/hive-env.sh </span><br><span class="line">echo $HADOOP_HOME</span><br><span class="line">/opt/hadoop</span><br><span class="line"></span><br><span class="line">修改/opt/hive/conf/hive-env.sh文件的HADOOP_HOME变量为：</span><br><span class="line">HADOOP_HOME=/opt/hadoop</span><br></pre></td></tr></table></figure><p>(2)hive-site.xml</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp /opt/hive/conf/hive-default.xml.template /opt/hive/conf/hive-site.xml</span><br></pre></td></tr></table></figure><h5 id="单用户模式【一般只用于测试环境】"><a href="#单用户模式【一般只用于测试环境】" class="headerlink" title="单用户模式【一般只用于测试环境】"></a>单用户模式【一般只用于测试环境】</h5><p>即, 元数据使用内嵌Derby数据库做存储</p><h5 id="多用户模式-配置"><a href="#多用户模式-配置" class="headerlink" title="多用户模式-配置"></a>多用户模式-配置</h5><p>即元数据非Derby, 而使用其他的关系型数据库存储(例如：MySQL、Oracle等)</p><p>Hive的元数据：表信息，表属性，分区，列等等信息，Owner</p><p>Hive的实际数据：在HDFS上</p><p><strong>创建数据库并授权</strong></p><p>slave1节点的mysql数据库下面需要提前创建一个名为hive的数据库, 账号密码均为hive</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@slave1 ~]# mysql -uroot -p</span><br><span class="line">mysql&gt; create database hive;</span><br><span class="line">mysql&gt; GRANT ALL PRIVILEGES ON hive.* TO &apos;hive&apos;@&apos;%&apos; IDENTIFIED BY &apos;hive&apos; WITH GRANT OPTION;</span><br><span class="line">mysql&gt; flush privileges;</span><br></pre></td></tr></table></figure><p><strong>Hive-site.xml的配置</strong></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>指定Hive连接数据库的连接字符串<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span> javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://slave1:3306/hive?createDatabaseIfNotExist=true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>指定以MySQL作为驱动类入口<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriver<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>指定数据库用户名<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>指定数据库密码<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p><strong>配置MySQL驱动</strong></p><p>驱动下载：<a href="https://dev.mysql.com/downloads/connector/j/5.1.html" target="_blank" rel="noopener">mysql-connector-java-5.1.47.zip</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">[root@slave3]#</span><span class="bash"> unzip mysql-connector-java-5.1.47.zip</span></span><br><span class="line"><span class="meta">[root@slave3]#</span><span class="bash"> cp mysql-connector-java-5.1.47/mysql-connector-java-5.1.47-bin.jar <span class="variable">$HIVE_HOME</span>/lib/</span></span><br><span class="line"><span class="meta">[root@slave3]#</span><span class="bash"> ls -lh <span class="variable">$HIVE_HOME</span>/lib/mysql-connector-java-5.1.47-bin.jar</span></span><br></pre></td></tr></table></figure><p><strong>初始化元数据库</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@slave3 conf]# schematool -initSchema --dbType mysql</span><br><span class="line"></span><br><span class="line">SLF4J: Class path contains multiple SLF4J bindings.</span><br><span class="line">SLF4J: Found binding in [jar:file:/opt/apache-hive-2.3.4-bin/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: Found binding in [jar:file:/opt/hadoop-2.7.3/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.</span><br><span class="line">SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]</span><br><span class="line">Metastore connection URL: jdbc:mysql://slave1:3306/hive?createDatabaseIfNotExist=true</span><br><span class="line">Metastore Connection Driver : org.apache.derby.jdbc.EmbeddedDriver</span><br><span class="line">Metastore connection User: hive</span><br><span class="line">Starting metastore schema initialization to 2.3.0</span><br><span class="line">Initialization script hive-schema-2.3.0.mysql.sql</span><br><span class="line">Initialization script completed</span><br><span class="line">schemaTool completed</span><br></pre></td></tr></table></figure><h5 id="配置远程模式-即启动Metastore-server服务【生产环境需要配置自启动】"><a href="#配置远程模式-即启动Metastore-server服务【生产环境需要配置自启动】" class="headerlink" title="配置远程模式- 即启动Metastore server服务【生产环境需要配置自启动】"></a>配置远程模式- 即启动Metastore server服务【生产环境需要配置自启动】</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@slave3 conf]# hive --service metastore &amp; </span><br><span class="line"></span><br><span class="line">Metastore Server默认端口号：9083</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> ss -lntup|grep 9083</span></span><br><span class="line">tcp    LISTEN     0   50    *:9083     *:*    users:(("java",pid=20847,fd=452))</span><br></pre></td></tr></table></figure><p>centos7自启</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> cat /etc/systemd/system/hive_metastore_server.service</span></span><br><span class="line">[Unit]</span><br><span class="line">Description=Start or stop hive metastore server</span><br><span class="line">After=network.target</span><br><span class="line">Wants=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/opt/hive/bin/hive --service metastore</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl <span class="builtin-name">enable</span> hive_metastore_server</span><br><span class="line">systemctl start hive_metastore_server</span><br><span class="line">systemctl status hive_metastore_server</span><br></pre></td></tr></table></figure><p><strong>测试Hive</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#查询数据库</span><br><span class="line">hive&gt; show databases;</span><br><span class="line">OK</span><br><span class="line">default</span><br><span class="line">Time taken: 4.555 seconds, Fetched: 1 row(s)</span><br><span class="line"></span><br><span class="line">#创建数据库</span><br><span class="line">hive&gt; create database garywu;</span><br><span class="line">OK</span><br><span class="line">Time taken: 0.335 seconds</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">#创建表</span><br><span class="line">hive&gt; use garywu;</span><br><span class="line">OK</span><br><span class="line">Time taken: 0.051 seconds</span><br><span class="line"></span><br><span class="line">hive&gt; create table hive_test (mykey string,myval string);</span><br><span class="line">OK</span><br><span class="line">Time taken: 1.374 seconds</span><br><span class="line"></span><br><span class="line">#插入数据</span><br><span class="line">hive&gt; insert into hive_test values(&quot;1&quot;,&quot;https://www.garywu.io&quot;);</span><br><span class="line">Query ID = root_20190327181939_360a8a91-7c80-4034-86fb-8394ef233494</span><br><span class="line">Total jobs = 3</span><br><span class="line">Launching Job 1 out of 3</span><br><span class="line">......</span><br><span class="line">......</span><br><span class="line">Stage-Stage-1: Map: 1   Cumulative CPU: 2.11 sec   HDFS Read: 4060 HDFS Write: 311254 SUCCESS</span><br><span class="line">Total MapReduce CPU Time Spent: 2 seconds 110 msec</span><br><span class="line">OK</span><br><span class="line">Time taken: 30.931 seconds</span><br><span class="line"></span><br><span class="line">#select查询</span><br><span class="line">hive&gt; select * from hive_test;</span><br><span class="line">OK</span><br><span class="line">1https://www.garywu.io</span><br><span class="line">Time taken: 0.411 seconds, Fetched: 1 row(s)</span><br><span class="line"></span><br><span class="line">#删除一个表</span><br><span class="line">hive&gt; drop table garywu;</span><br><span class="line">Moved: &apos;hdfs://nn/user/hive/warehouse/garywu.db/garywu&apos; to trash at: hdfs://nn/user/root/.Trash/Current</span><br><span class="line">OK</span><br><span class="line">Time taken: 1.929 seconds</span><br><span class="line">#注：这里可以看到删除操作直接将数据移动到了HDFS的垃圾桶</span><br><span class="line"></span><br><span class="line">#退出hive</span><br><span class="line">hive&gt; exit;</span><br></pre></td></tr></table></figure><p><strong>HDFS上查看刚刚写入的hdfs数据</strong></p><p><img src="https://raw.githubusercontent.com/wuyanteng/wuyanteng.github.io/master/images/hdfs_hive_db.png" alt="Hive_hdfs_db"></p><p><img src="https://raw.githubusercontent.com/wuyanteng/wuyanteng.github.io/master/images/hdfs_hive_db_block.png" alt="hive_hdfs_db_block"></p><p><strong>注：默认hive创建的数据会在HDFS的/user/hive/warehouse目录</strong>，除非修改了配置</p>]]></content>
    
    <summary type="html">
    
      &lt;h5 id=&quot;Hive连接模式&quot;&gt;&lt;a href=&quot;#Hive连接模式&quot; class=&quot;headerlink&quot; title=&quot;Hive连接模式&quot;&gt;&lt;/a&gt;Hive连接模式&lt;/h5&gt;&lt;ul&gt;
&lt;li&gt;单用户模式(元数据默认使用Derby关系型数据库存储)&lt;/li&gt;
&lt;li&gt;多用户模式&lt;/li&gt;
&lt;li&gt;远程模式&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&quot;环境准备&quot;&gt;&lt;a href=&quot;#环境准备&quot; class=&quot;headerlink&quot; title=&quot;环境准备&quot;&gt;&lt;/a&gt;环境准备&lt;/h5&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Hadoop V2.7.2&lt;/p&gt;
&lt;p&gt;要保证Hadoop服务已经启动。Hadoop环境搭建: &lt;a href=&quot;https://wuyanteng.github.io/2018/12/19/Hadoop%20HA%202.7.3%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2-%E7%BB%88%E6%9E%81%E7%89%88/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;参考&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;MySQL主从&lt;/p&gt;
&lt;p&gt;本次MySQL数据库部署在Slave1【IP:10.0.10.111】服务器上。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Hive 安装在Slave3【IP：10.0.10.113】上&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="高级运维" scheme="https://garywu520.github.io/blog/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"/>
    
      <category term="大数据" scheme="https://garywu520.github.io/blog/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Hive" scheme="https://garywu520.github.io/blog/tags/Hive/"/>
    
      <category term="Hadoop" scheme="https://garywu520.github.io/blog/tags/Hadoop/"/>
    
      <category term="spark" scheme="https://garywu520.github.io/blog/tags/spark/"/>
    
      <category term="tez" scheme="https://garywu520.github.io/blog/tags/tez/"/>
    
      <category term="单用户模式" scheme="https://garywu520.github.io/blog/tags/%E5%8D%95%E7%94%A8%E6%88%B7%E6%A8%A1%E5%BC%8F/"/>
    
      <category term="多用户模式" scheme="https://garywu520.github.io/blog/tags/%E5%A4%9A%E7%94%A8%E6%88%B7%E6%A8%A1%E5%BC%8F/"/>
    
      <category term="远程模式" scheme="https://garywu520.github.io/blog/tags/%E8%BF%9C%E7%A8%8B%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>Mars-hadoop hive架构介绍</title>
    <link href="https://garywu520.github.io/blog/2019/03/27/Mars-hadoop-hive%E6%9E%B6%E6%9E%84%E4%BB%8B%E7%BB%8D/"/>
    <id>https://garywu520.github.io/blog/2019/03/27/Mars-hadoop-hive架构介绍/</id>
    <published>2019-03-27T04:04:32.000Z</published>
    <updated>2019-03-27T04:34:27.656Z</updated>
    
    <content type="html"><![CDATA[<h5 id="Hive介绍"><a href="#Hive介绍" class="headerlink" title="Hive介绍"></a>Hive介绍</h5><p>Hive是建立在 Hadoop上的数据仓库基础构架，它提供了一系列的工具，可以通过SQL轻松的访问数据，可以完成数据仓库任务、报表及数据分析。可以用来进行数据提取转化加载（ETL），这是一种可以存储、查询和分析存储在 Hadoop 中的大规模数据的机制。</p><p>Hive 定义了简单的类 SQL 查询语言，称为 HQL，它允许熟悉 SQL 的用户查询数据。同时，这个语言也允许熟悉 MapReduce 开发者的开发自定义的 mapper 和 reducer 来处理内建的 mapper 和 reducer 无法完成的复杂的分析工作。</p><a id="more"></a><h5 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h5><p>Hive 构建在基于静态批处理的Hadoop 之上，Hadoop 通常都有较高的延迟并且在作业提交和调度的时候需要大量的开销。因此，Hive 并不能够在大规模数据集上实现低延迟快速的查询，例如，Hive 在几百MB 的数据集上执行查询一般有分钟级的时间延迟。因此，</p><p> Hive 并不适合那些需要低延迟的应用，例如，联机事务处理（OLTP）。Hive 查询操作过程严格遵守Hadoop MapReduce 的作业执行模型，Hive 将用户的HiveQL 语句通过解释器转换为MapReduce 作业提交到Hadoop 集群上，Hadoop 监控作业执行过程，然后返回作业执行结果给用户。Hive 并非为联机事务处理而设计，Hive 并不提供实时的查询和基于行级的数据更新操作。Hive 的最佳使用场合是大数据集的批处理作业，例如，网络日志分析。</p><h5 id="Hive设计特征"><a href="#Hive设计特征" class="headerlink" title="Hive设计特征"></a>Hive设计特征</h5><p>Hive 是一种底层封装了Hadoop 的数据仓库处理工具，使用类SQL 的HiveQL 语言实现数据查询，所有Hive 的数据都存储在Hadoop 兼容的文件系统（例如，Amazon S3、HDFS）中。Hive 在加载数据过程中不会对数据进行任何的修改，只是将数据移动到HDFS 中Hive 设定的目录下，因此，Hive 不支持对数据的改写和添加，所有的数据都是在加载的时候确定的。</p><p>Hive 的设计特点如下:</p><p>● 支持索引，加快数据查询。</p><p>● 支持不同的存储类型，例如，HDFS或其他的数据存储系统(如Hbase)</p><p>● 将元数据保存在关系数据库中，大大减少了在查询过程中执行语义检查的时间。</p><p>● 可以直接使用存储在Hadoop 文件系统中的数据。</p><p>● 支持LLAP(Live Long And Process), 使Hive实现内存计算</p><p>● 类SQL 的查询方式，将SQL 查询转换为MapReduce 的job 在Hadoop集群上执行。</p><h4 id="Hive体系结构"><a href="#Hive体系结构" class="headerlink" title="Hive体系结构"></a>Hive体系结构</h4><h5 id="用户接口"><a href="#用户接口" class="headerlink" title="用户接口"></a>用户接口</h5><p>用户接口主要有三个：CLI，Client 和 Web UI。</p><p>其中最常用的是 CLI，CLI启动的时候，会同时启动一个 Hive 副本。</p><p>Client 是 Hive 的客户端，用户连接至 Hive Server。在启动 Client 模式的时候，需要指出 Hive Server 所在节点，并且在该节点启动 Hive Server。</p><p>WUI 是通过浏览器访问 Hive。</p><h5 id="元数据存储"><a href="#元数据存储" class="headerlink" title="元数据存储"></a>元数据存储</h5><p>Hive将元数据存储在数据库中，如 mysql、derby。Hive 中的元数据包括表的名字，表的列和分区及其属性，表的属性（是否为外部表等），表的数据所在目录等。</p><h5 id="解释器、编译器、优化器、执行器"><a href="#解释器、编译器、优化器、执行器" class="headerlink" title="解释器、编译器、优化器、执行器"></a>解释器、编译器、优化器、执行器</h5><p>解释器、编译器、优化器完成 HQL 查询语句从词法分析、语法分析、编译、优化以及查询计划的生成。生成的查询计划存储在 HDFS 中，并在随后由 MapReduce 调用执行。</p><h5 id="Hive架构"><a href="#Hive架构" class="headerlink" title="Hive架构"></a>Hive架构</h5><p>Hive 将Hive Metastore元数据(包括表分区、表属性、格式等等)信息存储在了关系型数据库中，比如MySQL。</p><p>Driver包括解释器、编译器、优化器、执行器, 最终将HQL的查询语句转换成查询计划，而这个查询计划会存储在HDFS当中，最后交给MapReduce(作为作业)调用执行</p><p>注：包含 * 的查询，比如 select * from tbl 不会生成 MapReduce 任务</p><p><img src="https://raw.githubusercontent.com/wuyanteng/wuyanteng.github.io/master/images/hive%E6%9E%B6%E6%9E%84%E4%BD%93%E7%B3%BB.JPG" alt="hive架构体系"></p><h5 id="Hive原数据连接模式"><a href="#Hive原数据连接模式" class="headerlink" title="Hive原数据连接模式"></a>Hive原数据连接模式</h5><ul><li><p>单用户模式</p><p>一个用户只能运行一个会话去访问hive</p></li><li><p>多用户模式</p><p>多个用户可同时多个会话访问hive</p></li><li><p>远程模式</p></li></ul><h5 id="数据存储"><a href="#数据存储" class="headerlink" title="数据存储"></a>数据存储</h5><p>首先，Hive 没有专门的数据存储格式，也没有为数据建立索引，用户可以非常自由的组织 Hive 中的表，只需要在创建表的时候告诉 Hive 数据中的列分隔符和行分隔符，Hive 就可以解析数据。比如：.csv文件等。其次，Hive 中所有的数据都存储在 HDFS 中，Hive 中包含以下数据模型：表(Table)，外部表(External Table)，分区(Partition)，桶(Bucket)。</p><p> Hive 中的 Table 和数据库中的 Table 在概念上是类似的，每一个 Table 在 Hive 中都有一个相应的目录存储数据。例如，一个表 pvs，它在 HDFS 中的路径为：/wh/pvs，其中，wh 是在 hive-site.xml 中由 ${hive.metastore.warehouse.dir} 指定的数据仓库的目录，所有的 Table 数据（不包括 External Table）都保存在这个目录中。</p><p>Partition</p><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Partition 对应于数据库中的 Partition 列的密集索引，但是 Hive 中 Partition 的组织方式和数据库中的很不相同。在 Hive 中，表中的一个 Partition 对应于表下的一个目录，所有的 Partition 的数据都存储在对应的目录中。例如：pvs 表中包含 <span class="keyword">ds</span> 和 city 两个 Partition，则对应于 <span class="keyword">ds</span> = 20090801, ctry = <span class="keyword">US</span> 的 HDFS 子目录为：/<span class="keyword">wh</span>/pvs/<span class="keyword">ds</span>=20090801/ctry=<span class="keyword">US</span>；对应于 <span class="keyword">ds</span> = 20090801, ctry = <span class="keyword">CA</span> 的 HDFS 子目录为；/<span class="keyword">wh</span>/pvs/<span class="keyword">ds</span>=20090801/ctry=<span class="keyword">CA</span></span><br></pre></td></tr></table></figure><p>Buckets </p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Buckets 对指定列计算 hash，根据 hash 值切分数据，目的是为了并行，每一个 Bucket 对应一个文件。将<span class="built_in"> user </span>列分散至 32 个 bucket，首先对<span class="built_in"> user </span>列的值计算 hash，对应 hash 值为 0 的 HDFS 目录为：/wh/pvs/<span class="attribute">ds</span>=20090801/ctry=US/part-00000；hash 值为 20 的 HDFS 目录为：/wh/pvs/<span class="attribute">ds</span>=20090801/ctry=US/part-00020</span><br></pre></td></tr></table></figure><p>Table</p><figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">External <span class="keyword">Table</span> 指向已经在 HDFS 中存在的数据，可以创建<span class="comment"> Partition</span>。它和<span class="comment"> Table</span> 在元数据的组织上是相同的，而实际数据的存储则有较大的差异。</span><br><span class="line"></span><br><span class="line"><span class="keyword">Table</span> 的创建过程和数据加载过程（这两个过程可以在同一个语句中完成），在加载数据的过程中，实际数据会被移动到数据仓库目录中；之后对数据对访问将会直接在数据仓库目录中完成。删除表时，表中的数据和元数据将会被同时删除。</span><br></pre></td></tr></table></figure><p>External Table</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">External Table 只有一个过程，加载数据和创建表同时完成（<span class="keyword">CREATE</span> <span class="keyword">EXTERNAL</span> <span class="keyword">TABLE</span> ……LOCATION），实际数据是存储在 LOCATION 后面指定的 HDFS 路径中，并不会移动到数据仓库目录中。当删除一个 <span class="keyword">External</span> <span class="keyword">Table</span> 时，仅删除元数据，表中的数据不会真正被删除。</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h5 id=&quot;Hive介绍&quot;&gt;&lt;a href=&quot;#Hive介绍&quot; class=&quot;headerlink&quot; title=&quot;Hive介绍&quot;&gt;&lt;/a&gt;Hive介绍&lt;/h5&gt;&lt;p&gt;Hive是建立在 Hadoop上的数据仓库基础构架，它提供了一系列的工具，可以通过SQL轻松的访问数据，可以完成数据仓库任务、报表及数据分析。可以用来进行数据提取转化加载（ETL），这是一种可以存储、查询和分析存储在 Hadoop 中的大规模数据的机制。&lt;/p&gt;
&lt;p&gt;Hive 定义了简单的类 SQL 查询语言，称为 HQL，它允许熟悉 SQL 的用户查询数据。同时，这个语言也允许熟悉 MapReduce 开发者的开发自定义的 mapper 和 reducer 来处理内建的 mapper 和 reducer 无法完成的复杂的分析工作。&lt;/p&gt;
    
    </summary>
    
    
      <category term="高级运维" scheme="https://garywu520.github.io/blog/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"/>
    
      <category term="大数据" scheme="https://garywu520.github.io/blog/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="hadoop" scheme="https://garywu520.github.io/blog/tags/hadoop/"/>
    
      <category term="hdfs" scheme="https://garywu520.github.io/blog/tags/hdfs/"/>
    
      <category term="hive" scheme="https://garywu520.github.io/blog/tags/hive/"/>
    
      <category term="HQL" scheme="https://garywu520.github.io/blog/tags/HQL/"/>
    
  </entry>
  
  <entry>
    <title>mysql从库降低延迟</title>
    <link href="https://garywu520.github.io/blog/2019/03/26/mysql%E4%BB%8E%E5%BA%93%E9%99%8D%E4%BD%8E%E5%BB%B6%E8%BF%9F/"/>
    <id>https://garywu520.github.io/blog/2019/03/26/mysql从库降低延迟/</id>
    <published>2019-03-26T03:23:00.000Z</published>
    <updated>2019-03-28T10:07:18.058Z</updated>
    
    <content type="html"><![CDATA[<h5 id="slave复制延迟较大优化"><a href="#slave复制延迟较大优化" class="headerlink" title="slave复制延迟较大优化"></a>slave复制延迟较大优化</h5><p>默认mysql从库SQL为单线程，所以从库同步执行速度相对较慢，进而导致延迟增大。在MySQL5.7版本可以通过设置逻辑时钟来实现从库多线程复制</p><h5 id="查看从库复制线程状态"><a href="#查看从库复制线程状态" class="headerlink" title="查看从库复制线程状态"></a>查看从库复制线程状态</h5><p>主从环境部署完毕后，查看从库当前的线程状态</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show processlist;</span><br><span class="line">+--------+-------------+-----------+------+---------+-------+------------------------------</span><br><span class="line">| Id     | User        | | db   | Command | Time  | State                                   </span><br><span class="line">+--------+-------------+-----------+------+---------+-------+------------------------------</span><br><span class="line">| 148594 | system user | NULL | Connect | 22286 | Waiting for master to send event         </span><br><span class="line">| 148595 | system user | NULL | Connect |  2672 | Slave has read all relay log; waiting for</span><br><span class="line">| 150081 | root        | NULL | Query   |     0 | starting                                 </span><br><span class="line">+--------+-------------+-----------+------+---------+-------+------------------------------</span><br><span class="line">3 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure><p>可以看到当前只有一个复制线程</p><a id="more"></a><h4 id="配置从库多线程复制"><a href="#配置从库多线程复制" class="headerlink" title="配置从库多线程复制"></a>配置从库多线程复制</h4><h5 id="1-在从库上停止复制"><a href="#1-在从库上停止复制" class="headerlink" title="1. 在从库上停止复制"></a>1. 在从库上停止复制</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; stop slave;</span><br></pre></td></tr></table></figure><h5 id="2-设置并发同步类型为逻辑时钟方式"><a href="#2-设置并发同步类型为逻辑时钟方式" class="headerlink" title="2. 设置并发同步类型为逻辑时钟方式"></a>2. 设置并发同步类型为逻辑时钟方式</h5><p>先看下现在 slave 的并发类型</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">mysql&gt;</span><span class="bash"> show variables like <span class="string">'slave_parallel_type'</span>;</span></span><br><span class="line">+---------------------+----------+</span><br><span class="line">| Variable_name       | Value    |</span><br><span class="line">+---------------------+----------+</span><br><span class="line">| slave_parallel_type | DATABASE |</span><br><span class="line">+---------------------+----------+</span><br><span class="line">1 row in set (0.18 sec)</span><br></pre></td></tr></table></figure><p>默认是database，每个线程只能处理一个数据库</p><p>配置成基于逻辑时钟的方式</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">mysql&gt;</span><span class="bash"> <span class="built_in">set</span> global slave_parallel_type=<span class="string">'logical_clock'</span>;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">mysql&gt;</span><span class="bash"> show variables like <span class="string">'slave_parallel_type'</span>;</span></span><br></pre></td></tr></table></figure><h5 id="3-设置复制线程的数量"><a href="#3-设置复制线程的数量" class="headerlink" title="3.  设置复制线程的数量"></a>3.  设置复制线程的数量</h5><p>先看下当前的并发量</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like &apos;slave_parallel_workers&apos;;</span><br><span class="line">+------------------------+-------+</span><br><span class="line">| Variable_name          | Value |</span><br><span class="line">+------------------------+-------+</span><br><span class="line">| slave_parallel_workers | 0     |</span><br><span class="line">+------------------------+-------+</span><br><span class="line">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure><p>修改并发量为8</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; set global slave_parallel_workers=8;</span><br><span class="line"></span><br><span class="line">mysql&gt; show variables like &apos;slave_parallel_workers&apos;;</span><br></pre></td></tr></table></figure><h5 id="4-启动从库复制"><a href="#4-启动从库复制" class="headerlink" title="4. 启动从库复制"></a>4. 启动从库复制</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; start slave;</span><br></pre></td></tr></table></figure><p>验证配置结果</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show processlist;</span><br></pre></td></tr></table></figure><h4 id="多线程复制好处"><a href="#多线程复制好处" class="headerlink" title="多线程复制好处"></a>多线程复制好处</h4><p>多源线程，即每个sql线程处理不同的database，提高了并发性能，即使某database的某条语句暂时卡住，也不会影响到后续对其它的database进行操作。多线程复制在一定程度上解决了从库延迟主库并且很难追上的问题。</p><h4 id="其他问题与解决方案"><a href="#其他问题与解决方案" class="headerlink" title="其他问题与解决方案"></a>其他问题与解决方案</h4><p>如果一个生产场景，在某一时刻，有大量的数据向同一个数据库执行写操作，这个时候，多线程复制功能便失去了从库降低延迟的作用。这个时候还需要继续优化</p><h5 id="配置sync-binlog和innodb-flush-log参数"><a href="#配置sync-binlog和innodb-flush-log参数" class="headerlink" title="配置sync_binlog和innodb_flush_log参数"></a>配置sync_binlog和innodb_flush_log参数</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like &apos;sync_binlog&apos;;</span><br><span class="line">mysql&gt; set global sync_binlog=0;</span><br></pre></td></tr></table></figure><p>含义：当事务提交之后，MySQL不做fsync之类的磁盘同步指令刷新binlog_cache中的信息到磁盘，而让Filesystem自行决定什么时候来做同步，或者cache满了之后才同步到磁盘。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; SHOW VARIABLES LIKE &apos;%innodb_flush_log_at_trx_commit%&apos;;</span><br><span class="line">mysql&gt; SET GLOBAL innodb_flush_log_at_trx_commit = 0;</span><br></pre></td></tr></table></figure><p>含义：innodb_flush_log_at_trx_commit设置为【0或2, 默认为1】不同的值，性能差别很明显。可以通过设置为0或者2来提高事物提高性能。但是这种设置丧失了ACID特性。</p><h4 id="附加：从库配置my-cnf文件参数"><a href="#附加：从库配置my-cnf文件参数" class="headerlink" title="附加：从库配置my.cnf文件参数"></a>附加：从库配置my.cnf文件参数</h4><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">slave-parallel-type</span>=LOGICAL_CLOCK</span><br><span class="line"><span class="attr">slave-parallel-workers</span>=<span class="number">8</span></span><br><span class="line"><span class="attr">sync_binlog</span>=<span class="number">0</span></span><br><span class="line"><span class="attr">innodb_flush_log_at_trx_commit</span>=<span class="number">0</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h5 id=&quot;slave复制延迟较大优化&quot;&gt;&lt;a href=&quot;#slave复制延迟较大优化&quot; class=&quot;headerlink&quot; title=&quot;slave复制延迟较大优化&quot;&gt;&lt;/a&gt;slave复制延迟较大优化&lt;/h5&gt;&lt;p&gt;默认mysql从库SQL为单线程，所以从库同步执行速度相对较慢，进而导致延迟增大。在MySQL5.7版本可以通过设置逻辑时钟来实现从库多线程复制&lt;/p&gt;
&lt;h5 id=&quot;查看从库复制线程状态&quot;&gt;&lt;a href=&quot;#查看从库复制线程状态&quot; class=&quot;headerlink&quot; title=&quot;查看从库复制线程状态&quot;&gt;&lt;/a&gt;查看从库复制线程状态&lt;/h5&gt;&lt;p&gt;主从环境部署完毕后，查看从库当前的线程状态&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;mysql&amp;gt; show processlist;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;+--------+-------------+-----------+------+---------+-------+------------------------------&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;| Id     | User        | | db   | Command | Time  | State                                   &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;+--------+-------------+-----------+------+---------+-------+------------------------------&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;| 148594 | system user | NULL | Connect | 22286 | Waiting for master to send event         &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;| 148595 | system user | NULL | Connect |  2672 | Slave has read all relay log; waiting for&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;| 150081 | root        | NULL | Query   |     0 | starting                                 &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;+--------+-------------+-----------+------+---------+-------+------------------------------&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3 rows in set (0.00 sec)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;p&gt;可以看到当前只有一个复制线程&lt;/p&gt;
    
    </summary>
    
    
      <category term="高级运维" scheme="https://garywu520.github.io/blog/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"/>
    
      <category term="mysql" scheme="https://garywu520.github.io/blog/tags/mysql/"/>
    
      <category term="主从复制" scheme="https://garywu520.github.io/blog/tags/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"/>
    
      <category term="降低延迟" scheme="https://garywu520.github.io/blog/tags/%E9%99%8D%E4%BD%8E%E5%BB%B6%E8%BF%9F/"/>
    
      <category term="mysql 5.7" scheme="https://garywu520.github.io/blog/tags/mysql-5-7/"/>
    
      <category term="多线程主从复制" scheme="https://garywu520.github.io/blog/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"/>
    
  </entry>
  
  <entry>
    <title>ESXI vm磁盘精简置备转换为厚置备</title>
    <link href="https://garywu520.github.io/blog/2019/03/20/ESXI-vm%E7%A3%81%E7%9B%98%E7%B2%BE%E7%AE%80%E7%BD%AE%E5%A4%87%E8%BD%AC%E6%8D%A2%E4%B8%BA%E5%8E%9A%E7%BD%AE%E5%A4%87/"/>
    <id>https://garywu520.github.io/blog/2019/03/20/ESXI-vm磁盘精简置备转换为厚置备/</id>
    <published>2019-03-20T07:33:57.000Z</published>
    <updated>2019-03-20T07:50:31.228Z</updated>
    
    <content type="html"><![CDATA[<h5 id="前提条件"><a href="#前提条件" class="headerlink" title="前提条件"></a>前提条件</h5><ul><li>关闭vm虚拟机电源</li><li>移除快照</li><li>要转换的vm磁盘类型为精简置备</li></ul><h5 id="操作过程"><a href="#操作过程" class="headerlink" title="操作过程"></a>操作过程</h5><ul><li><p>浏览要扩充vm的虚拟磁盘文件夹，找到并选中xxx.vmdk文件</p></li><li><p>右键xxx.vmdk文件，选择“扩充磁盘” 。此过程花费时间较长，需要耐心等待…</p><p>注：此操作会将磁盘类型从精简置备变更为厚置备磁盘，此时扩充的虚拟磁盘将占据最初为其置备的整个数据存储空间。</p></li></ul><p><img src="https://raw.githubusercontent.com/wuyanteng/wuyanteng.github.io/master/images/esxi%E7%BD%AE%E5%A4%87%E8%BD%AC%E6%8D%A2.png" alt="置备转换"></p><p>关于磁盘置备类型，参考：<a href="https://wuyanteng.github.io/2019/03/20/ESXI%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%A3%81%E7%9B%98%E7%BD%AE%E5%A4%87/#more" target="_blank" rel="noopener">ESXI虚拟机磁盘置备</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h5 id=&quot;前提条件&quot;&gt;&lt;a href=&quot;#前提条件&quot; class=&quot;headerlink&quot; title=&quot;前提条件&quot;&gt;&lt;/a&gt;前提条件&lt;/h5&gt;&lt;ul&gt;
&lt;li&gt;关闭vm虚拟机电源&lt;/li&gt;
&lt;li&gt;移除快照&lt;/li&gt;
&lt;li&gt;要转换的vm磁盘类型为精简置备&lt;/li&gt;
&lt;/
      
    
    </summary>
    
    
      <category term="高级运维" scheme="https://garywu520.github.io/blog/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"/>
    
      <category term="ESXI" scheme="https://garywu520.github.io/blog/tags/ESXI/"/>
    
      <category term="vm" scheme="https://garywu520.github.io/blog/tags/vm/"/>
    
      <category term="精简置备" scheme="https://garywu520.github.io/blog/tags/%E7%B2%BE%E7%AE%80%E7%BD%AE%E5%A4%87/"/>
    
      <category term="厚置备" scheme="https://garywu520.github.io/blog/tags/%E5%8E%9A%E7%BD%AE%E5%A4%87/"/>
    
  </entry>
  
  <entry>
    <title>ESXI虚拟机磁盘置备</title>
    <link href="https://garywu520.github.io/blog/2019/03/20/ESXI%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%A3%81%E7%9B%98%E7%BD%AE%E5%A4%87/"/>
    <id>https://garywu520.github.io/blog/2019/03/20/ESXI虚拟机磁盘置备/</id>
    <published>2019-03-20T06:35:17.000Z</published>
    <updated>2019-03-20T06:59:54.707Z</updated>
    
    <content type="html"><![CDATA[<h5 id="虚拟磁盘置备策略分类"><a href="#虚拟磁盘置备策略分类" class="headerlink" title="虚拟磁盘置备策略分类"></a>虚拟磁盘置备策略分类</h5><ul><li>精简置备</li><li>厚置备置零</li><li>厚置备延迟置零</li></ul><h5 id="怎么理解？举个例子"><a href="#怎么理解？举个例子" class="headerlink" title="怎么理解？举个例子"></a>怎么理解？举个例子</h5><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">比如：在酒店办酒席~ ~ ~</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 精简置备</span></span><br><span class="line">   来了多少客人就开多少桌酒席，每次来了新客人就需要重新划分空间，摆桌子摆椅子什么的。</span><br><span class="line"><span class="comment">-- 厚置备置零</span></span><br><span class="line">   腾出一层楼面，桌子椅子全部摆好，客人来了可以直接就座。</span><br><span class="line"><span class="comment">-- 厚置备延迟置零</span></span><br><span class="line">   先腾出一层楼面来摆酒席，等客人来的时候再摆桌子摆椅子。</span><br></pre></td></tr></table></figure><p>这个例子参考自：<a href="https://www.zhihu.com/people/xi-gua-61-35/activities" target="_blank" rel="noopener">知乎-西瓜</a></p><a id="more"></a><p><img src="https://raw.githubusercontent.com/wuyanteng/wuyanteng.github.io/master/images/esxi_disk_zhibei.png" alt="esxi_disk_zhibei"></p><h5 id="官方解释"><a href="#官方解释" class="headerlink" title="官方解释"></a>官方解释</h5><ul><li><p>精简置备</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">使用此格式可节省存储空间。对于精简磁盘，可以根据输入的虚拟磁盘大小值置备磁盘所需的数据存储空间。但是，精简磁盘开始时很小，只使用与初始操作所需的大小完全相同的存储空间。如果精简磁盘以后需要更多空间，它可以增长到其最大容量，并占据为其置备的整个数据存储空间。</span><br></pre></td></tr></table></figure></li><li><p>厚置备置零</p><figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">一种厚虚拟磁盘类型，创建虚拟磁盘时，会立即将物理设备上保留的数据置零<span class="comment">(即清空)</span>。创建这种格式的虚拟磁盘所需的时间可能会比创建其他类型的磁盘所用时间长。</span><br></pre></td></tr></table></figure></li><li><p>厚置备延迟置零</p><figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">以默认的厚格式创建虚拟磁盘。在创建虚拟磁盘时分配该磁盘所需的空间。创建过程中不会立即清除物理设备上保留的数据，但以后首次从虚拟机写入时则会按需置零<span class="comment">(即按需清空)</span>。</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h5 id=&quot;虚拟磁盘置备策略分类&quot;&gt;&lt;a href=&quot;#虚拟磁盘置备策略分类&quot; class=&quot;headerlink&quot; title=&quot;虚拟磁盘置备策略分类&quot;&gt;&lt;/a&gt;虚拟磁盘置备策略分类&lt;/h5&gt;&lt;ul&gt;
&lt;li&gt;精简置备&lt;/li&gt;
&lt;li&gt;厚置备置零&lt;/li&gt;
&lt;li&gt;厚置备延迟置零&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&quot;怎么理解？举个例子&quot;&gt;&lt;a href=&quot;#怎么理解？举个例子&quot; class=&quot;headerlink&quot; title=&quot;怎么理解？举个例子&quot;&gt;&lt;/a&gt;怎么理解？举个例子&lt;/h5&gt;&lt;figure class=&quot;highlight ada&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;比如：在酒店办酒席~ ~ ~&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;-- 精简置备&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   来了多少客人就开多少桌酒席，每次来了新客人就需要重新划分空间，摆桌子摆椅子什么的。&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;-- 厚置备置零&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   腾出一层楼面，桌子椅子全部摆好，客人来了可以直接就座。&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;-- 厚置备延迟置零&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   先腾出一层楼面来摆酒席，等客人来的时候再摆桌子摆椅子。&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;p&gt;这个例子参考自：&lt;a href=&quot;https://www.zhihu.com/people/xi-gua-61-35/activities&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;知乎-西瓜&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="高级运维" scheme="https://garywu520.github.io/blog/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"/>
    
      <category term="ESXI" scheme="https://garywu520.github.io/blog/tags/ESXI/"/>
    
      <category term="vm" scheme="https://garywu520.github.io/blog/tags/vm/"/>
    
      <category term="精简置备" scheme="https://garywu520.github.io/blog/tags/%E7%B2%BE%E7%AE%80%E7%BD%AE%E5%A4%87/"/>
    
      <category term="厚置备" scheme="https://garywu520.github.io/blog/tags/%E5%8E%9A%E7%BD%AE%E5%A4%87/"/>
    
      <category term="磁盘置备" scheme="https://garywu520.github.io/blog/tags/%E7%A3%81%E7%9B%98%E7%BD%AE%E5%A4%87/"/>
    
      <category term="disk" scheme="https://garywu520.github.io/blog/tags/disk/"/>
    
  </entry>
  
  <entry>
    <title>ESXI制作Linux系统模板</title>
    <link href="https://garywu520.github.io/blog/2019/03/20/ESXI%E5%88%B6%E4%BD%9CLinux%E7%B3%BB%E7%BB%9F%E6%A8%A1%E6%9D%BF/"/>
    <id>https://garywu520.github.io/blog/2019/03/20/ESXI制作Linux系统模板/</id>
    <published>2019-03-20T02:36:28.000Z</published>
    <updated>2019-03-20T03:36:32.075Z</updated>
    
    <content type="html"><![CDATA[<h4 id="有两种方式实现"><a href="#有两种方式实现" class="headerlink" title="有两种方式实现"></a>有两种方式实现</h4><h5 id="方式一：OVF导出导入"><a href="#方式一：OVF导出导入" class="headerlink" title="方式一：OVF导出导入"></a>方式一：OVF导出导入</h5><p>这种方式是，在VMware Workstation Pro中创建好虚拟机，并将所需环境配置和优化完毕，然后关闭虚拟机并将其导出为OVF格式镜像，这种镜像是直接可以在ESXI中使用的。</p><p>ESXI使用：登陆ESXI客户端 – 文件 – 部署OVF模板 – 上传OVF格式镜像即可。</p><a id="more"></a><h5 id="方式二：通过vmdk文件"><a href="#方式二：通过vmdk文件" class="headerlink" title="方式二：通过vmdk文件"></a>方式二：通过vmdk文件</h5><p>在ESXI中，创建完成的虚拟机默认格式即为vmdk,  所以可以直接从现有的vmdk中创建vm</p><p>(1) 首先在ESXI中创建一个虚拟机，并配置和优化所需环境，把这个虚拟机当做模板</p><p>(2) 找到此虚拟机安装文件所在的位置，并关闭此虚拟机</p><p>(3) 创建新虚拟机</p><p><img src="https://raw.githubusercontent.com/wuyanteng/wuyanteng.github.io/master/images/%E8%87%AA%E5%AE%9A%E4%B9%89create_vm.png" alt="create_vm"></p><p>​         接下来根据提示配置vm硬件参数</p><p><img src="https://raw.githubusercontent.com/wuyanteng/wuyanteng.github.io/master/images/vm_select_disk2.png" alt="vm_select_disk2"></p><p><img src="https://raw.githubusercontent.com/wuyanteng/wuyanteng.github.io/master/images/vm_select_disk3.png" alt="vm_select_disk3"></p><p>紧接着点击完成，启动使用模板创建的vm吧</p>]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;有两种方式实现&quot;&gt;&lt;a href=&quot;#有两种方式实现&quot; class=&quot;headerlink&quot; title=&quot;有两种方式实现&quot;&gt;&lt;/a&gt;有两种方式实现&lt;/h4&gt;&lt;h5 id=&quot;方式一：OVF导出导入&quot;&gt;&lt;a href=&quot;#方式一：OVF导出导入&quot; class=&quot;headerlink&quot; title=&quot;方式一：OVF导出导入&quot;&gt;&lt;/a&gt;方式一：OVF导出导入&lt;/h5&gt;&lt;p&gt;这种方式是，在VMware Workstation Pro中创建好虚拟机，并将所需环境配置和优化完毕，然后关闭虚拟机并将其导出为OVF格式镜像，这种镜像是直接可以在ESXI中使用的。&lt;/p&gt;
&lt;p&gt;ESXI使用：登陆ESXI客户端 – 文件 – 部署OVF模板 – 上传OVF格式镜像即可。&lt;/p&gt;
    
    </summary>
    
    
      <category term="ESXI" scheme="https://garywu520.github.io/blog/tags/ESXI/"/>
    
      <category term="vm" scheme="https://garywu520.github.io/blog/tags/vm/"/>
    
      <category term="VMware vSphere Client" scheme="https://garywu520.github.io/blog/tags/VMware-vSphere-Client/"/>
    
      <category term="VMware Workstation Pro" scheme="https://garywu520.github.io/blog/tags/VMware-Workstation-Pro/"/>
    
      <category term="vmdk" scheme="https://garywu520.github.io/blog/tags/vmdk/"/>
    
  </entry>
  
  <entry>
    <title>Mars-Hadoop Sqoop Job</title>
    <link href="https://garywu520.github.io/blog/2019/03/13/Mars-Hadoop-Sqoop-Job/"/>
    <id>https://garywu520.github.io/blog/2019/03/13/Mars-Hadoop-Sqoop-Job/</id>
    <published>2019-03-13T08:26:53.000Z</published>
    <updated>2019-03-13T09:23:09.350Z</updated>
    
    <content type="html"><![CDATA[<h5 id="Sqoop-Job介绍"><a href="#Sqoop-Job介绍" class="headerlink" title="Sqoop Job介绍"></a>Sqoop Job介绍</h5><figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">作用：记录Sqoop命令的配置信息，包括关系型数据库连接地址、用户名、密码、数据库和表等等信息。</span><br><span class="line"></span><br><span class="line">Job：存储在User私有目录<span class="comment">(即linux用户的家目录)</span>$HOME/.sqoop/下，可将此配置为共享的metastore中<span class="comment">(供集群中多用户使用)</span></span><br><span class="line"></span><br><span class="line">应用场景：多次执行同一个导入导出命令<span class="comment">(尤其是增量导入时)</span></span><br></pre></td></tr></table></figure><h5 id="Sqoop-Job帮助"><a href="#Sqoop-Job帮助" class="headerlink" title="Sqoop Job帮助"></a>Sqoop Job帮助</h5><figure class="highlight haml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sqoop job </span><br><span class="line">         -<span class="ruby">-create &lt;job-id&gt;   <span class="comment">#创建作业(ID或名称)</span></span></span><br><span class="line"><span class="ruby">         --delete &lt;job-id&gt;   <span class="comment">#删除作业(ID或名称)</span></span></span><br><span class="line"><span class="ruby">         --exec &lt;job-id&gt;     <span class="comment">#执行作业</span></span></span><br><span class="line"><span class="ruby">         --list              <span class="comment">#列出当前已创建的作业</span></span></span><br><span class="line"><span class="ruby">         --meta-connect &lt;jdbc-uri&gt;   <span class="comment">#指定共享metastore</span></span></span><br><span class="line"><span class="ruby">         --help</span></span><br></pre></td></tr></table></figure><a id="more"></a><p>示例</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">增量导入</span><br><span class="line">sqoop import <span class="params">--connect</span> jdbc<span class="function">:mysql</span>:<span class="string">//10.0.10.100</span><span class="function">:3306</span>/bigdata <span class="params">--username</span> root -P <span class="params">--table</span> bigdata  <span class="params">--target-dir</span> <span class="string">/sqoopim</span> <span class="params">--check-column</span> class_id <span class="params">--incremental</span> append <span class="params">--last-value</span> 18 -m 1</span><br></pre></td></tr></table></figure><figure class="highlight basic"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">19</span>/<span class="number">03</span>/<span class="number">12</span> <span class="number">16</span>:<span class="number">33</span>:<span class="number">50</span> INFO tool.ImportTool:  --inc<span class="comment">remental append</span></span><br><span class="line"><span class="number">19</span>/<span class="number">03</span>/<span class="number">12</span> <span class="number">16</span>:<span class="number">33</span>:<span class="number">50</span> INFO tool.ImportTool:   --check-column class_id</span><br><span class="line"><span class="number">19</span>/<span class="number">03</span>/<span class="number">12</span> <span class="number">16</span>:<span class="number">33</span>:<span class="number">50</span> INFO tool.ImportTool:   --last-value <span class="number">22</span></span><br><span class="line"><span class="number">19</span>/<span class="number">03</span>/<span class="number">12</span> <span class="number">16</span>:<span class="number">33</span>:<span class="number">50</span> INFO tool.ImportTool: (Consider saving this with <span class="comment">'sqoop job --create')</span></span><br></pre></td></tr></table></figure><h5 id="创建job"><a href="#创建job" class="headerlink" title="创建job"></a>创建job</h5><figure class="highlight brainfuck"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">格式：</span></span><br><span class="line"><span class="comment">sqoop</span> <span class="comment">job</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">create</span> <span class="comment">job1</span> <span class="literal">-</span><span class="literal">-</span> <span class="title">[</span><span class="comment">sqoop</span> <span class="comment">common</span><span class="title">]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">sqoop</span> <span class="comment">job</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">create</span> <span class="comment">job1</span> <span class="literal">-</span><span class="literal">-</span> <span class="comment">import</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">connect</span> <span class="comment">jdbc:mysql://10</span><span class="string">.</span><span class="comment">0</span><span class="string">.</span><span class="comment">10</span><span class="string">.</span><span class="comment">100:3306/bigdata</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">username</span> <span class="comment">root</span> <span class="literal">-</span><span class="comment">P</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">table</span> <span class="comment">bigdata</span>  <span class="literal">-</span><span class="literal">-</span><span class="comment">target</span><span class="literal">-</span><span class="comment">dir</span> <span class="comment">/sqoopim</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">check</span><span class="literal">-</span><span class="comment">column</span> <span class="comment">class_id</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">incremental</span> <span class="comment">append</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">last</span><span class="literal">-</span><span class="comment">value</span> <span class="comment">22</span> <span class="literal">-</span><span class="comment">m</span> <span class="comment">1</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">注意：创建job时，如果有</span><span class="literal">-</span><span class="literal">-</span><span class="comment">last</span><span class="literal">-</span><span class="comment">value参数，需要将此参数的值更新;而执行job的过程中，job会自动更新此信息</span></span><br></pre></td></tr></table></figure><h5 id="查看job"><a href="#查看job" class="headerlink" title="查看job"></a>查看job</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">查看已有列表</span><br><span class="line"><span class="comment"># sqoop job --list</span></span><br><span class="line">   Available <span class="built_in">jobs</span>:</span><br><span class="line">      job1</span><br></pre></td></tr></table></figure><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">查看具体<span class="keyword">job内容</span></span><br><span class="line"><span class="keyword">sqoop </span><span class="keyword">job </span>--<span class="keyword">show </span><span class="keyword">job1</span></span><br></pre></td></tr></table></figure><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Job: job1</span><br><span class="line">Tool: import</span><br><span class="line">Options:</span><br><span class="line">----------------------------</span><br><span class="line">verbose = false</span><br><span class="line">hcatalog<span class="selector-class">.drop</span><span class="selector-class">.and</span><span class="selector-class">.create</span><span class="selector-class">.table</span> = false</span><br><span class="line">incremental<span class="selector-class">.last</span><span class="selector-class">.value</span> = <span class="number">22</span></span><br><span class="line">db<span class="selector-class">.connect</span><span class="selector-class">.string</span> = jdbc:mysql:<span class="comment">//10.0.10.100:3306/bigdata</span></span><br><span class="line">......</span><br><span class="line">......</span><br><span class="line">hdfs<span class="selector-class">.target</span><span class="selector-class">.dir</span> = /sqoopim</span><br><span class="line">hive<span class="selector-class">.fail</span><span class="selector-class">.table</span><span class="selector-class">.exists</span> = false</span><br><span class="line">db<span class="selector-class">.batch</span> = false</span><br></pre></td></tr></table></figure><h5 id="执行job任务"><a href="#执行job任务" class="headerlink" title="执行job任务"></a>执行job任务</h5><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sqoop job <span class="comment">--exec job1</span></span><br></pre></td></tr></table></figure><h5 id="错误解决"><a href="#错误解决" class="headerlink" title="错误解决"></a>错误解决</h5><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">报错：</span><br><span class="line">Exception <span class="keyword">in</span> thread <span class="string">"main"</span> java<span class="selector-class">.lang</span><span class="selector-class">.NoClassDefFoundError</span>: org/json/JSONObject</span><br><span class="line">at org<span class="selector-class">.apache</span><span class="selector-class">.sqoop</span><span class="selector-class">.util</span><span class="selector-class">.SqoopJsonUtil</span><span class="selector-class">.getJsonStringforMap</span>(SqoopJsonUtil<span class="selector-class">.java</span>:<span class="number">43</span>)</span><br><span class="line">at org<span class="selector-class">.apache</span><span class="selector-class">.sqoop</span><span class="selector-class">.SqoopOptions</span><span class="selector-class">.writeProperties</span>(SqoopOptions<span class="selector-class">.java</span>:<span class="number">785</span>)</span><br><span class="line">at org<span class="selector-class">.apache</span><span class="selector-class">.sqoop</span><span class="selector-class">.metastore</span><span class="selector-class">.hsqldb</span><span class="selector-class">.Hsqldbe</span><span class="selector-class">.createInternal</span>(HsqldbJobStorage<span class="selector-class">.java</span>:<span class="number">399</span>)</span><br></pre></td></tr></table></figure><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">原因是<span class="selector-tag">sqoop</span>缺少<span class="selector-tag">java-json</span><span class="selector-class">.jar</span>包</span><br></pre></td></tr></table></figure><p>下载：<a href="http://www.java2s.com/Code/Jar/j/Downloadjavajsonjar.htm" target="_blank" rel="noopener">java-json.jar</a></p><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">解决方法：</span><br><span class="line">把java-json.jar添加到../sqoop/<span class="class"><span class="keyword">lib</span>目录：<span class="title">cp</span> <span class="title">java</span>-<span class="title">json</span>.<span class="title">jar</span>  ../<span class="title">sqoop</span>/<span class="title">lib</span></span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h5 id=&quot;Sqoop-Job介绍&quot;&gt;&lt;a href=&quot;#Sqoop-Job介绍&quot; class=&quot;headerlink&quot; title=&quot;Sqoop Job介绍&quot;&gt;&lt;/a&gt;Sqoop Job介绍&lt;/h5&gt;&lt;figure class=&quot;highlight gcode&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;作用：记录Sqoop命令的配置信息，包括关系型数据库连接地址、用户名、密码、数据库和表等等信息。&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Job：存储在User私有目录&lt;span class=&quot;comment&quot;&gt;(即linux用户的家目录)&lt;/span&gt;$HOME/.sqoop/下，可将此配置为共享的metastore中&lt;span class=&quot;comment&quot;&gt;(供集群中多用户使用)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;应用场景：多次执行同一个导入导出命令&lt;span class=&quot;comment&quot;&gt;(尤其是增量导入时)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;h5 id=&quot;Sqoop-Job帮助&quot;&gt;&lt;a href=&quot;#Sqoop-Job帮助&quot; class=&quot;headerlink&quot; title=&quot;Sqoop Job帮助&quot;&gt;&lt;/a&gt;Sqoop Job帮助&lt;/h5&gt;&lt;figure class=&quot;highlight haml&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;sqoop job &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;         -&lt;span class=&quot;ruby&quot;&gt;-create &amp;lt;job-id&amp;gt;   &lt;span class=&quot;comment&quot;&gt;#创建作业(ID或名称)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;ruby&quot;&gt;         --delete &amp;lt;job-id&amp;gt;   &lt;span class=&quot;comment&quot;&gt;#删除作业(ID或名称)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;ruby&quot;&gt;         --exec &amp;lt;job-id&amp;gt;     &lt;span class=&quot;comment&quot;&gt;#执行作业&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;ruby&quot;&gt;         --list              &lt;span class=&quot;comment&quot;&gt;#列出当前已创建的作业&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;ruby&quot;&gt;         --meta-connect &amp;lt;jdbc-uri&amp;gt;   &lt;span class=&quot;comment&quot;&gt;#指定共享metastore&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;ruby&quot;&gt;         --help&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="高级运维" scheme="https://garywu520.github.io/blog/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"/>
    
      <category term="大数据" scheme="https://garywu520.github.io/blog/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="hdfs" scheme="https://garywu520.github.io/blog/tags/hdfs/"/>
    
      <category term="Sqoop" scheme="https://garywu520.github.io/blog/tags/Sqoop/"/>
    
      <category term="hadoop Job" scheme="https://garywu520.github.io/blog/tags/hadoop-Job/"/>
    
  </entry>
  
  <entry>
    <title>Mars-hadoop sqoop导出实战</title>
    <link href="https://garywu520.github.io/blog/2019/03/13/Mars-hadoop-sqoop%E5%AF%BC%E5%87%BA%E5%AE%9E%E6%88%98/"/>
    <id>https://garywu520.github.io/blog/2019/03/13/Mars-hadoop-sqoop导出实战/</id>
    <published>2019-03-13T07:38:36.000Z</published>
    <updated>2019-03-13T08:20:11.960Z</updated>
    
    <content type="html"><![CDATA[<h5 id="一、可能的数据处理架构"><a href="#一、可能的数据处理架构" class="headerlink" title="一、可能的数据处理架构"></a>一、可能的数据处理架构</h5><figure class="highlight xl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">S<span class="function"><span class="title">qoop</span> <span class="keyword">import</span> -&gt;</span>H<span class="function"><span class="title">ive</span>/HDFS -&gt;</span>MR J<span class="function"><span class="title">ob</span>/Spark Job/Streaming Job/ML Job/SQL -&gt;</span> Result Data</span><br></pre></td></tr></table></figure><h5 id="二、Sqoop导出通用参数"><a href="#二、Sqoop导出通用参数" class="headerlink" title="二、Sqoop导出通用参数"></a>二、Sqoop导出通用参数</h5><ul><li>–connect 连接关系型数据库</li><li>–username 关系型数据库用户</li><li>–password/-P  关系型数据库密码</li></ul><a id="more"></a><h5 id="三、Sqoop导出控制参数"><a href="#三、Sqoop导出控制参数" class="headerlink" title="三、Sqoop导出控制参数"></a>三、Sqoop导出控制参数</h5><p>–columns 字段1,字段2,字段3</p><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">注意: 没有被包含在<span class="comment">--columns后面(例如class_month,last_mod_ts)的这些列名或字段要么具备默认值，要么就允许插入空值，数据库会拒绝接受sqoop导出的数据，导致Sqoop作业失败</span></span><br></pre></td></tr></table></figure><p>–export-dir</p><figure class="highlight brainfuck"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">指定导出目录，在执行导出的时候，必须指定这个参数，同时具备</span><span class="literal">-</span><span class="literal">-</span><span class="comment">table或</span><span class="literal">-</span><span class="literal">-</span><span class="comment">call参数的两者之一。</span></span><br><span class="line"><span class="comment"></span><span class="literal">-</span><span class="literal">-</span><span class="comment">table指的是导出数据库当中对应的表</span></span><br><span class="line"><span class="comment"></span><span class="literal">-</span><span class="literal">-</span><span class="comment">call</span> <span class="comment">指的是某个存储过程</span></span><br></pre></td></tr></table></figure><p>–input-null-string、–input-null-non-string</p><figure class="highlight autoit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">这两个参数可选，如果没有指定第一个参数[--input-<span class="literal">null</span>-<span class="built_in">string</span>]，对于字符串类型的列来说，“<span class="literal">NULL</span>”这个字符串就会被翻译为空值。</span><br><span class="line">如果没有第二个参数[--input-<span class="literal">null</span>-non-<span class="built_in">string</span>]，无论是“<span class="literal">NULL</span>”字符串还是空字符串也好，对于非字符串类型的字段来说，这两个类型的字符串都会被翻译成空值</span><br></pre></td></tr></table></figure><h5 id="四、全表从HDFS导出-示例"><a href="#四、全表从HDFS导出-示例" class="headerlink" title="四、全表从HDFS导出-示例"></a>四、全表从HDFS导出-示例</h5><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sqoop export <span class="params">--connect</span> jdbc<span class="function">:mysql</span>:<span class="string">//serverip</span><span class="function">:3306</span>/bigdata <span class="params">--username</span> root -P <span class="params">--table</span> bigdata <span class="params">--export-dir</span> <span class="string">/user/root/bigdata</span></span><br></pre></td></tr></table></figure><h5 id="五、全表从HDFS更新-增量导出"><a href="#五、全表从HDFS更新-增量导出" class="headerlink" title="五、全表从HDFS更新/增量导出"></a>五、全表从HDFS更新/增量导出</h5><ul><li><p>–update-key </p><p>更新标识，即根据某个字段进行更新，例如class_id，可以同时指定多个更新标识，用逗号分隔</p></li><li><p>–updatemod </p><p>有两种模式: </p><p>一种是updateonly(默认模式)，仅仅更新已存在的数据记录，不会插入新纪录</p><p>另一种模式时allowinsert,允许插入新纪录</p></li><li><p>Sqoop的Export工具，对应两种语句</p></li></ul><figure class="highlight n1ql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">一种是<span class="keyword">Insert</span>语句，如果表当中存在PK[主键]约束，且表中已包含数据，此时，导出报错。 需要用到—<span class="keyword">update</span>-<span class="keyword">key</span>和updatemod</span><br></pre></td></tr></table></figure><figure class="highlight n1ql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">如果指定了<span class="keyword">update</span>-<span class="keyword">key</span>，那么Sqoop就会修改在数据表中已存在的数据，此时的每一个更新数据记录都会变成一个<span class="keyword">Update</span>语句，用这个语句去更新目标表中已存在的数据，这是根据–<span class="keyword">update</span>-<span class="keyword">key</span>所指定的这个列进行更新的。</span><br><span class="line"></span><br><span class="line">(<span class="number">1</span>）若<span class="keyword">update</span>-<span class="keyword">key</span>所指定的字段不是PK[主键]字段，若同时updatemod使用updateonly模式时，就仅进行更新；若updatemod使用allowinsert模式，那么实质上就是一个<span class="keyword">insert</span>操作 </span><br><span class="line"></span><br><span class="line">(<span class="number">2</span>）若<span class="keyword">update</span>-<span class="keyword">key</span>所指定的字段是PK[主键]字段，同时updatemod是allowinsert时，实质上是一个<span class="keyword">insert</span> &amp; <span class="keyword">update</span>的操作；若updatemod是updateonly时，实质仅为<span class="keyword">update</span>操作</span><br></pre></td></tr></table></figure><h5 id="更新-增量导出-示例"><a href="#更新-增量导出-示例" class="headerlink" title="更新/增量导出-示例"></a>更新/增量导出-示例</h5><p>updateonly模式</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sqoop export <span class="params">--connect</span> jdbc<span class="function">:mysql</span>:<span class="string">//serverip</span><span class="function">:3306</span>/bigdata <span class="params">--username</span> root -P <span class="params">--table</span> bigdata <span class="params">--export-dir</span> <span class="string">/user/root/bigdata/</span> <span class="params">--update-key</span> class_id <span class="params">--update-mode</span> updateonly</span><br></pre></td></tr></table></figure><p>allowinsert模式</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sqoop export <span class="params">--connect</span> jdbc<span class="function">:mysql</span>:<span class="string">//serverip</span><span class="function">:3306</span>/bigdata <span class="params">--username</span> root -P <span class="params">--table</span> bigdata2  <span class="params">--export-dir</span> <span class="string">/user/root/bigdata/</span> <span class="params">--update-key</span> class_id <span class="params">--update-mode</span> updateinsert</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h5 id=&quot;一、可能的数据处理架构&quot;&gt;&lt;a href=&quot;#一、可能的数据处理架构&quot; class=&quot;headerlink&quot; title=&quot;一、可能的数据处理架构&quot;&gt;&lt;/a&gt;一、可能的数据处理架构&lt;/h5&gt;&lt;figure class=&quot;highlight xl&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;S&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;title&quot;&gt;qoop&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; -&amp;gt;&lt;/span&gt;H&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;title&quot;&gt;ive&lt;/span&gt;/HDFS -&amp;gt;&lt;/span&gt;MR J&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;title&quot;&gt;ob&lt;/span&gt;/Spark Job/Streaming Job/ML Job/SQL -&amp;gt;&lt;/span&gt; Result Data&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;h5 id=&quot;二、Sqoop导出通用参数&quot;&gt;&lt;a href=&quot;#二、Sqoop导出通用参数&quot; class=&quot;headerlink&quot; title=&quot;二、Sqoop导出通用参数&quot;&gt;&lt;/a&gt;二、Sqoop导出通用参数&lt;/h5&gt;&lt;ul&gt;
&lt;li&gt;–connect 连接关系型数据库&lt;/li&gt;
&lt;li&gt;–username 关系型数据库用户&lt;/li&gt;
&lt;li&gt;–password/-P  关系型数据库密码&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="高级运维" scheme="https://garywu520.github.io/blog/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"/>
    
      <category term="hadoop" scheme="https://garywu520.github.io/blog/tags/hadoop/"/>
    
      <category term="hdfs" scheme="https://garywu520.github.io/blog/tags/hdfs/"/>
    
      <category term="sqoop" scheme="https://garywu520.github.io/blog/tags/sqoop/"/>
    
  </entry>
  
</feed>
